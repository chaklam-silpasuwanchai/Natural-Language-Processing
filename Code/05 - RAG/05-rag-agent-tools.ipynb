{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "# Agents\n",
    "- The core idea of agents is to use a language model to choose `a sequence of actions` to take. \n",
    "- In chains, a sequence of actions is hardcoded (in code). \n",
    "- In agents, a language model is used as a reasoning engine to determine `which actions to take and in which order.`\n",
    "\n",
    "There are several key components here: Agent, Tools, AgentExecutor, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Agent\n",
    "This is the chain responsible for deciding what step to take next, which powered by a language model and a prompt. The inputs to this chain are:\n",
    "\n",
    "- `Tools`: Descriptions of available tools\n",
    "- `User input`: The high level objective\n",
    "- `Intermediate steps`: Any (action, tool output) pairs previously executed in order to achieve the user input\n",
    "\n",
    "The output is the next action(s) to take or the final response to send to the user (AgentActions or AgentFinish). An action specifies a tool and the input to that tool.\n",
    "\n",
    "Different agents have different prompting styles for reasoning, different ways of encoding inputs, and different ways of parsing the output. [Explore Agent Types here](https://python.langchain.com/docs/modules/agents/agent_types/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tools\n",
    "Tools are functions that an agent can invoke. There are two important design considerations around tools:\n",
    "1. Giving the agent access to the right tools\n",
    "2. Describing the tools in a way that is most helpful to the agent\n",
    "   \n",
    "Without thinking through both, you won't be able to build a working agent. If you don't give the agent access to a correct set of tools, it will never be able to accomplish the objectives you give it. If you don't describe the tools well, the agent won't know how to use them properly.\n",
    "\n",
    "LangChain provides a wide set of built-in tools, but also makes it easy to define your own (including custom descriptions). [Explore the tools integrations section](https://python.langchain.com/docs/integrations/tools/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "nlp_document = './docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf'\n",
    "loader = PyMuPDFLoader(nlp_document)\n",
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import torch\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 700,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "docs = text_splitter.split_documents(documents) \n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/todsavadt/.local/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "model_name = 'hkunlp/instructor-base'\n",
    "\n",
    "embedding_model = HuggingFaceInstructEmbeddings(\n",
    "    model_name = model_name,              \n",
    "    model_kwargs = {\n",
    "        'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    },\n",
    ")\n",
    "\n",
    "vectordb = FAISS.from_documents(docs, embedding_model)\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever Tool\n",
    "Now we need to create a tool for our retriever. The main things we need to pass in are a name for the retriever as well as a description. These will both be used by the language model, so they should be informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='search_nlp_stanford', description='Searches and returns documents regarding the nlp-stanford.', args_schema=<class 'langchain.tools.retriever.RetrieverInput'>, func=<bound method BaseRetriever.get_relevant_documents of VectorStoreRetriever(tags=['FAISS', 'HuggingFaceInstructEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f8ded7887f0>)>, coroutine=<bound method BaseRetriever.aget_relevant_documents of VectorStoreRetriever(tags=['FAISS', 'HuggingFaceInstructEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f8ded7887f0>)>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"search_nlp_stanford\",\n",
    "    \"Searches and returns documents regarding the nlp-stanford.\",\n",
    ")\n",
    "tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AgentExecutor\n",
    "The agent executor is the runtime for an agent. This is what actually calls the agent, executes the actions it chooses, passes the action outputs back to the agent, and repeats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 02:47:05.585228: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-28 02:47:05.642065: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-28 02:47:05.642097: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-28 02:47:05.644584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-28 02:47:05.651891: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-28 02:47:06.367416: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain import HuggingFacePipeline\n",
    "\n",
    "model_id = \"models/fastchat-t5-3b-v1.0\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    ")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "bitsandbyte_config = BitsAndBytesConfig(\n",
    "        load_in_4bit = True,\n",
    "        bnb_4bit_quant_type = \"nf4\",\n",
    "        bnb_4bit_compute_dtype = torch.float16,\n",
    "        bnb_4bit_use_double_quant = True\n",
    "    )\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config = bitsandbyte_config,\n",
    "    device_map = 'auto',\n",
    "    load_in_8bit = True,\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text2text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_new_tokens=256, \n",
    "    model_kwargs = { \n",
    "        \"temperature\":0, \n",
    "        \"repetition_penalty\": 1.5\n",
    "    }, \n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Constructor\n",
    "Here, we will use the high level create_conversational_retrieval_agent API to construct the agent.\n",
    "\n",
    "Notice that beside the list of tools, the only thing we need to pass in is a language model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "\n",
    "agent_executor = create_conversational_retrieval_agent(\n",
    "    llm, \n",
    "    tools, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<pad> Chaky, how can I help you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"hi, I'm Chaky\",\n",
       " 'chat_history': [HumanMessage(content=\"hi, I'm Chaky\"),\n",
       "  AIMessage(content='<pad> Chaky, how can I help you today?')],\n",
       " 'output': '<pad> Chaky, how can I help you today?',\n",
       " 'intermediate_steps': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now try it out!\n",
    "result = agent_executor(\n",
    "    {\n",
    "        \"input\": \"hi, I'm Chaky\"\n",
    "    }\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<pad> AI:<< pad>\n",
      " AI:<< pad>\n",
      " Chaky,  constituency  parser  and  dependency  parser  are  two  different  types  of  parsers  used  in  machine  learning  algorithms.\n",
      " Constituency  parser  is  a  type  of  parser  that  is  used  to  parse  the  input  data  and  generate  a  representation  of  the  data.  It  is  used  to  represent  the  relationships  between  the  input  data  and  the  output  data.  The  input  data  is  typically  represented  as  a  list  of  strings,  and  the  output  data  is  represented  as  a  list  of  boolean  values.\n",
      " Dependency  parser,  on  the  other  hand,  is  a  type  of  parser  that  is  used  to  parse  the  input  data  and  generate  a  representation  of  the\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How is it diffferent between constituency parser and dependency parser?',\n",
       " 'chat_history': [HumanMessage(content=\"hi, I'm Chaky\"),\n",
       "  AIMessage(content='<pad> Chaky, how can I help you today?'),\n",
       "  HumanMessage(content='what did the president say about kentaji brown jackson in the most recent state of the union?'),\n",
       "  AIMessage(content=\"<pad> AI:< pad>  Chaky,  I'm  sorry,  but  I  don't  have  access  to  the  most  recent  state  of  the  union  address  of  the  President  of  the  United  States.  However,  I  can  tell  you  that  the  President  of  the  United  States  has  made  several  statements  about  Kentai  Brown  Jackson  in  the  past,  including  his  support  for  civil  rights  and  the  fight  against  racial  inequality.\\n\"),\n",
       "  HumanMessage(content='How is it diffferent between constituency parser and dependency parser?'),\n",
       "  AIMessage(content='<pad> AI:<< pad>\\n AI:<< pad>\\n Chaky,  constituency  parser  and  dependency  parser  are  two  different  types  of  parsers  used  in  machine  learning  algorithms.\\n Constituency  parser  is  a  type  of  parser  that  is  used  to  parse  the  input  data  and  generate  a  representation  of  the  data.  It  is  used  to  represent  the  relationships  between  the  input  data  and  the  output  data.  The  input  data  is  typically  represented  as  a  list  of  strings,  and  the  output  data  is  represented  as  a  list  of  boolean  values.\\n Dependency  parser,  on  the  other  hand,  is  a  type  of  parser  that  is  used  to  parse  the  input  data  and  generate  a  representation  of  the')],\n",
       " 'output': '<pad> AI:<< pad>\\n AI:<< pad>\\n Chaky,  constituency  parser  and  dependency  parser  are  two  different  types  of  parsers  used  in  machine  learning  algorithms.\\n Constituency  parser  is  a  type  of  parser  that  is  used  to  parse  the  input  data  and  generate  a  representation  of  the  data.  It  is  used  to  represent  the  relationships  between  the  input  data  and  the  output  data.  The  input  data  is  typically  represented  as  a  list  of  strings,  and  the  output  data  is  represented  as  a  list  of  boolean  values.\\n Dependency  parser,  on  the  other  hand,  is  a  type  of  parser  that  is  used  to  parse  the  input  data  and  generate  a  representation  of  the',\n",
       " 'intermediate_steps': []}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent_executor(\n",
    "    {\n",
    "        \"input\": \"How is it different between constituency parser and dependency parser?\"\n",
    "    }\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating from components\n",
    "\n",
    "What actually is going on underneath the hood? Let’s take a look so we can understand how to modify going forward.\n",
    "\n",
    "There are a few components:\n",
    "\n",
    "- The memory\n",
    "- The prompt template\n",
    "- The agent\n",
    "- The agent executor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Memory\n",
    "In this example, we want the agent to remember not only previous conversations, but also previous intermediate steps. For that, we can use AgentTokenBufferMemory. \n",
    "\n",
    "Note that if you want to change whether the agent remembers intermediate steps, or how the long the buffer is, or anything like that you should change this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed for both the memory and the prompt\n",
    "memory_key = \"history\"\n",
    "\n",
    "from langchain.agents.openai_functions_agent.agent_token_buffer_memory import (\n",
    "    AgentTokenBufferMemory,\n",
    ")\n",
    "\n",
    "memory = AgentTokenBufferMemory(memory_key=memory_key, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Prompt Template\n",
    "For the prompt template, we will use the OpenAIFunctionsAgent default way of creating one, but pass in a system prompt and a placeholder for memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'history', 'input'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessage(content=\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about probabilistic models, language models, or any other related topic, \\n    I'm here to help break down complex concepts into easy-to-understand explanations.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\"), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content=(\n",
    "    \"\"\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
    "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
    "    Whether it's about probabilistic models, language models, or any other related topic, \n",
    "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
    "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=memory_key)],\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# We will use the OpenAIFunctionsAgent\n",
    "agent = OpenAIFunctionsAgent(\n",
    "    llm=llm, \n",
    "    tools=tools, \n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    ")\n",
    "\n",
    "# Importantly, we pass in return_intermediate_steps=True since we are recording that with our memory object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<pad> System:  I'm  ChakyBot,  a  chatbot  designed  to  assist  Chaky  and  Gun  with  their  Natural  Language  Processing  (NLP)  questions.  I'm  here  to  help  break  down  complex  concepts  into  easy-to-understand  explanations,  and  I'm  always  happy  to  answer  any  questions  you  may  have.  Just  let  me  know  what  you're  curious  about,  and  I'll  do  my  best  to  guide  you  through  it!\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who are you by the way?',\n",
       " 'history': [HumanMessage(content='Who are you by the way?'),\n",
       "  AIMessage(content=\"<pad> System:  I'm  ChakyBot,  a  chatbot  designed  to  assist  Chaky  and  Gun  with  their  Natural  Language  Processing  (NLP)  questions.  I'm  here  to  help  break  down  complex  concepts  into  easy-to-understand  explanations,  and  I'm  always  happy  to  answer  any  questions  you  may  have.  Just  let  me  know  what  you're  curious  about,  and  I'll  do  my  best  to  guide  you  through  it!\\n\")],\n",
       " 'output': \"<pad> System:  I'm  ChakyBot,  a  chatbot  designed  to  assist  Chaky  and  Gun  with  their  Natural  Language  Processing  (NLP)  questions.  I'm  here  to  help  break  down  complex  concepts  into  easy-to-understand  explanations,  and  I'm  always  happy  to  answer  any  questions  you  may  have.  Just  let  me  know  what  you're  curious  about,  and  I'll  do  my  best  to  guide  you  through  it!\\n\",\n",
       " 'intermediate_steps': []}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent_executor({\"input\": \"Who are you by the way?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<pad> AI:<< pad>\n",
      " System:  Transformers  are  a  type  of  neural  network  architecture  that  are  used  to  process  and  generate  natural  language  text.  They  are  a  type  of  language  model  that  can  be  trained  to  understand  and  generate  text  in  a  given  context.  Transformers  are  often  used  in  NLP  tasks  such  as  sentiment  analysis,  text  classification,  and  language  modeling.  They  are  designed  to  learn  the  structure  and  meaning  of  text  data,  and  they  can  be  used  to  build  more  complex  models  that  can  handle  more  complex  tasks  such  as  text  generation  and  generation.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is transformers?',\n",
       " 'history': [HumanMessage(content='Who are you by the way?'),\n",
       "  AIMessage(content=\"<pad> System:  I'm  ChakyBot,  a  chatbot  designed  to  assist  Chaky  and  Gun  with  their  Natural  Language  Processing  (NLP)  questions.  I'm  here  to  help  break  down  complex  concepts  into  easy-to-understand  explanations,  and  I'm  always  happy  to  answer  any  questions  you  may  have.  Just  let  me  know  what  you're  curious  about,  and  I'll  do  my  best  to  guide  you  through  it!\\n\"),\n",
       "  HumanMessage(content='What is transformers?'),\n",
       "  AIMessage(content='<pad> AI:<< pad>\\n System:  Transformers  are  a  type  of  neural  network  architecture  that  are  used  to  process  and  generate  natural  language  text.  They  are  a  type  of  language  model  that  can  be  trained  to  understand  and  generate  text  in  a  given  context.  Transformers  are  often  used  in  NLP  tasks  such  as  sentiment  analysis,  text  classification,  and  language  modeling.  They  are  designed  to  learn  the  structure  and  meaning  of  text  data,  and  they  can  be  used  to  build  more  complex  models  that  can  handle  more  complex  tasks  such  as  text  generation  and  generation.\\n')],\n",
       " 'output': '<pad> AI:<< pad>\\n System:  Transformers  are  a  type  of  neural  network  architecture  that  are  used  to  process  and  generate  natural  language  text.  They  are  a  type  of  language  model  that  can  be  trained  to  understand  and  generate  text  in  a  given  context.  Transformers  are  often  used  in  NLP  tasks  such  as  sentiment  analysis,  text  classification,  and  language  modeling.  They  are  designed  to  learn  the  structure  and  meaning  of  text  data,  and  they  can  be  used  to  build  more  complex  models  that  can  handle  more  complex  tasks  such  as  text  generation  and  generation.\\n',\n",
       " 'intermediate_steps': []}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent_executor({\"input\": \"What is transformers?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
