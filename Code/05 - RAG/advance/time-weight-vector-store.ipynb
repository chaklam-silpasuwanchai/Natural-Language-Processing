{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-weighted vector store retriever\n",
    "\n",
    "This retriever uses a combination of semantic similarity and a time decay.\n",
    "\n",
    "The algorithm for scoring them is:\n",
    "`semantic_similarity + (1.0 - decay_rate) ^ hours_passed`\n",
    "\n",
    "Notably, hours_passed refers to the hours passed since the object in the retriever was last accessed, not since it was created. This means that frequently accessed objects remain \"fresh\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPEN_AI_KEY\")\n",
    "organization = os.getenv(\"OPEN_AI_ORG\")\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_organization=organization,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A `retriever` is an interface that returns documents given an unstructured query. It is more general than a `vector store`. \n",
    "- A `retriever` does not need to be able to store documents, only to return (or retrieve) them. \n",
    "- `Vector stores` can be used as the backbone of a retriever, but there are other types of retrievers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from datetime import datetime, timedelta\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Define your embedding model\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    openai_api_key=api_key,\n",
    "    openai_organization=organization,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low decay rate\n",
    "A low decay rate (in this, to be extreme, we will set it close to 0) means memories will be \"remembered\" for longer. A decay rate of 0 means memories never be forgotten, making this retriever equivalent to the vector lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the vectorstore as empty\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(\n",
    "    embedding_function = embeddings_model.embed_query, \n",
    "    index = index, \n",
    "    docstore = InMemoryDocstore({}), \n",
    "    index_to_docstore_id = {}\n",
    ")\n",
    "retriever = TimeWeightedVectorStoreRetriever(\n",
    "    vectorstore=vectorstore, \n",
    "    decay_rate=.0000000000000000000000001, \n",
    "    k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c00bf3e9-d340-4292-9e43-22c92c4c0d2b']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "retriever.add_documents([Document(page_content=\"hello world\", metadata={\"last_accessed_at\": yesterday})])\n",
    "retriever.add_documents([Document(page_content=\"hello foo\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='hello world', metadata={'last_accessed_at': datetime.datetime(2023, 12, 13, 13, 24, 59, 630256), 'created_at': datetime.datetime(2023, 12, 13, 13, 24, 57, 943449), 'buffer_idx': 0})]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Hello World\" is returned first because it is most salient, and the decay rate is close to 0., meaning it's still recent enough\n",
    "retriever.get_relevant_documents(\"hello world\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High decay rate\n",
    "With a high decay rate (e.g., several 9's), the recency score quickly goes to 0! If you set this all the way to 1, recency is 0 for all objects, once again making this equivalent to a vector lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the vectorstore as empty\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "# Index that stores the full vectors and performs exhaustive search\n",
    "vectorstore = FAISS(\n",
    "    embedding_function = embeddings_model.embed_query, \n",
    "    index = index, \n",
    "    docstore = InMemoryDocstore({}), \n",
    "    index_to_docstore_id = {}\n",
    ")\n",
    "retriever = TimeWeightedVectorStoreRetriever(\n",
    "    vectorstore=vectorstore, \n",
    "    decay_rate=.999, \n",
    "    k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01bf581e-3398-43cd-b13f-228ef0094ed7']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "retriever.add_documents([Document(page_content=\"hello world\", metadata={\"last_accessed_at\": yesterday})])\n",
    "retriever.add_documents([Document(page_content=\"hello foo\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_function': OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x11ead8bd0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x11eafa690>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization='org-TgLUfkcRqwKG1gpiZ4ff9N44', allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, http_client=None),\n",
       " 'index': <faiss.swigfaiss.IndexFlat; proxy of <Swig Object of type 'faiss::IndexFlat *' at 0x11eccdef0> >,\n",
       " 'docstore': <langchain.docstore.in_memory.InMemoryDocstore at 0x1203279d0>,\n",
       " 'index_to_docstore_id': {0: 'd850435f-d58a-4380-af8a-b08a14d65ddd',\n",
       "  1: 'af76e16a-cb91-4035-94af-b0a413edc5be',\n",
       "  2: 'a60197b5-e73d-4572-b603-14500684efad'},\n",
       " 'distance_strategy': <DistanceStrategy.EUCLIDEAN_DISTANCE: 'EUCLIDEAN_DISTANCE'>,\n",
       " 'override_relevance_score_fn': None,\n",
       " '_normalize_L2': False}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_retriever = retriever.vectorstore.as_retriever()\n",
    "new_retriever.vectorstore.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='hello foo', metadata={'last_accessed_at': datetime.datetime(2023, 12, 13, 13, 25, 43, 249315), 'created_at': datetime.datetime(2023, 12, 13, 13, 25, 42, 891064), 'buffer_idx': 2})]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Hello Foo\" is returned first because \"hello world\" is mostly forgotten\n",
    "retriever.get_relevant_documents(\"hello world\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual time\n",
    "Using some utils in LangChain, you can mock out the time component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.utils import mock_now\n",
    "# import datetime\n",
    "# # Notice the last access time is that date time\n",
    "# with mock_now(datetime.datetime(2023, 12, 13, 13, 11)):\n",
    "#     print(retriever.get_relevant_documents(\"hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='hello foo', metadata={'last_accessed_at': datetime.datetime(2023, 12, 13, 13, 25, 36, 857100), 'created_at': datetime.datetime(2023, 12, 13, 13, 25, 34, 23614), 'buffer_idx': 0}),\n",
       " Document(page_content='hello world', metadata={'last_accessed_at': datetime.datetime(2023, 12, 12, 13, 25, 42, 168102), 'created_at': datetime.datetime(2023, 12, 13, 13, 25, 42, 168199), 'buffer_idx': 1}),\n",
       " Document(page_content='hello foo', metadata={'last_accessed_at': datetime.datetime(2023, 12, 13, 13, 25, 43, 249315), 'created_at': datetime.datetime(2023, 12, 13, 13, 25, 42, 891064), 'buffer_idx': 2})]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.memory_stream"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Vectorstore from retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "vectordb_path = 'vectordb_path'\n",
    "db_file_name = 'test'\n",
    "\n",
    "retriever.vectorstore.save_local(\n",
    "    folder_path = os.path.join(vectordb_path, db_file_name),\n",
    "    index_name = 'index' #default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb_path = 'vectordb_path'\n",
    "db_file_name = 'test'\n",
    "\n",
    "vector = FAISS.load_local(\n",
    "    folder_path = os.path.join(vectordb_path, db_file_name),\n",
    "    embeddings  = embeddings_model,\n",
    "    index_name = \"index\",\n",
    ")\n",
    "\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='hello world', metadata={'last_accessed_at': datetime.datetime(2023, 12, 12, 13, 25, 42, 168102), 'created_at': datetime.datetime(2023, 12, 13, 13, 25, 42, 168199), 'buffer_idx': 1}),\n",
       " Document(page_content='hello foo', metadata={'last_accessed_at': datetime.datetime(2023, 12, 13, 13, 25, 36, 857100), 'created_at': datetime.datetime(2023, 12, 13, 13, 25, 34, 23614), 'buffer_idx': 0}),\n",
       " Document(page_content='hello foo', metadata={'last_accessed_at': datetime.datetime(2023, 12, 13, 13, 25, 43, 249315), 'created_at': datetime.datetime(2023, 12, 13, 13, 25, 42, 891064), 'buffer_idx': 2})]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = TimeWeightedVectorStoreRetriever(\n",
    "    vectorstore=vector, \n",
    "    decay_rate=.999, \n",
    "    k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='hello world', metadata={'last_accessed_at': datetime.datetime(2023, 12, 12, 13, 36, 39, 213944), 'created_at': datetime.datetime(2023, 12, 13, 13, 36, 39, 215179), 'buffer_idx': 0}),\n",
       " Document(page_content='hello foo', metadata={'last_accessed_at': datetime.datetime(2023, 12, 13, 13, 36, 40, 78398), 'created_at': datetime.datetime(2023, 12, 13, 13, 36, 40, 78398), 'buffer_idx': 1})]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search('',k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m vectorstore\u001b[39m.\u001b[39msimilarity_search(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,k\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     retriever\u001b[39m.\u001b[39;49madd_documents(doc)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/time_weighted_retriever.py:124\u001b[0m, in \u001b[0;36mTimeWeightedVectorStoreRetriever.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m dup_docs \u001b[39m=\u001b[39m [deepcopy(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m i, doc \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dup_docs):\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlast_accessed_at\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39;49mmetadata:\n\u001b[1;32m    125\u001b[0m         doc\u001b[39m.\u001b[39mmetadata[\u001b[39m\"\u001b[39m\u001b[39mlast_accessed_at\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m current_time\n\u001b[1;32m    126\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcreated_at\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39mmetadata:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'metadata'"
     ]
    }
   ],
   "source": [
    "for doc in vectorstore.similarity_search('',k=100):\n",
    "    retriever.add_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
