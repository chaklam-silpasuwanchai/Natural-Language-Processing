{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Part 1: Introduction to Langchain\n",
    "LangChain is a framework for developing applications powered by language models. It enables applications that:\n",
    "1. `Are context-aware`: connect a LM to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.)\n",
    "2. `Reason`: rely on a LM to reason (about how to answer based on provided context, what actions to take, etc.)\n",
    "\n",
    "## Use cases\n",
    "1. Document question answering (Law, Medicine)\n",
    "2. Chatbots (Marketing, HR Recruiter)\n",
    "3. Analyzing structured data (SQL, Report Documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common and most important chain that LangChain helps create contains three things:\n",
    "\n",
    "1. `LLM`: The LM is the core reasoning engine here. In order to work with LangChain, you need to understand the different types of LMs and how to work with them.\n",
    "2. `Prompt Templates`: This provides instructions to the language model. This controls what the language model outputs, so understanding how to construct prompts and different prompting strategies is crucial.\n",
    "3. `Output Parsers`: These translate the raw response from the LLM to a more workable format, making it easy to use the output downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.315'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install langchain==0.0.315\n",
    "import langchain\n",
    "langchain.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Prompts\n",
    "\n",
    "A prompt for a language model is a set of instructions or input provided by a user to guide the model's response, helping it understand the context and generate relevant and coherent language-based output, such as answering questions, completing sentences, or engaging in a conversation.\n",
    "\n",
    "LangChain provides several classes and functions to help construct and work with prompts.\n",
    "\n",
    "- `Prompt templates`: Parametrized model inputs\n",
    "- `Example selectors`: Dynamically select examples to include in prompts (not include this lecture)\n",
    "\n",
    "### 2.1 Prompt templates\n",
    "Prompt templates are pre-defined recipes for generating prompts for language models.\n",
    "\n",
    "A template may include `instructions`, `few-shot examples`, and `specific context` and `questions appropriate` for a given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guntsv/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['adjective', 'content'], template='Tell me a {adjective} joke about {content}.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For additional validation, specify input_variables explicitly. \n",
    "#These variables will be compared against the variables present in the template string during instantiation\n",
    "#raising an exception if there is a mismatch.\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"content\"],\n",
    "    template=\"Tell me a {adjective} joke about {content}.\",\n",
    ")\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ChatPromptTemplate\n",
    "\n",
    "The prompt to chat models is a list of chat messages.\n",
    "\n",
    "Each chat message is associated with content, and an additional parameter called `role`.\n",
    "\n",
    "For example, in the OpenAI Chat Completions API, a chat message can be associated with an AI assistant, a human or a system role.\n",
    "\n",
    "LangChain provides several objects to easily distinguish between different roles:\n",
    "\n",
    "- `SystemMessage`: A ChatMessage coming from the system.\n",
    "- `AIMessage`: A ChatMessage coming from an AI/assistant.\n",
    "- `HumanMessage`: A ChatMessage coming from a human/user.\n",
    "- `FunctionMessage`: A ChatMessage coming from a function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You serve as the teacher assistant to Chaky, who instructs an NLP course. \\nYour primary responsibility is to assist students in successfully completing the NLP course.'),\n",
       " HumanMessage(content='How to get A if I fail every quizs?')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ChatMessage\n",
    ")\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "'''\n",
    "HumanMessage: A message sent from the perspective of the human\n",
    "AIMessage: A message sent from the perspective of the AI the human is interacting with\n",
    "SystemMessage: A message setting the objectives the AI should follow\n",
    "ChatMessage: A message allowing for arbitrary setting of role. You wonâ€™t be using this too much\n",
    "'''\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=(\"\"\"You serve as the teacher assistant to Chaky, who instructs an NLP course. \n",
    "Your primary responsibility is to assist students in successfully completing the NLP course.\"\"\")),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_template.format_messages(text=\"How to get A if I fail every quizs?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix \n",
    "- [Custom prompt template](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/custom_prompt_template)\n",
    "- [Few-shot prompt templates](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/few_shot_examples)\n",
    "- [Few-shot examples for chat models](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/few_shot_examples_chat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
