{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "# Agents \n",
    "- The core idea of agents is to use a language model to choose a sequence of actions to take. \n",
    "- In chains, a sequence of actions is hardcoded (in code). \n",
    "- In agents, a language model is used as a reasoning engine to determine which actions to take and in which order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #langchain library\n",
    "# !pip install langchain==0.1.2\n",
    "# !pip install langchain-openai\n",
    "# !pip install langchain-community\n",
    "# #Tool API\n",
    "# !pip install wikipedia\n",
    "# #LLM\n",
    "# !pip install accelerate==0.25.0\n",
    "# !pip install transformers==4.36.2\n",
    "# !pip install bitsandbytes==0.41.2\n",
    "# #Text Embedding\n",
    "# !pip install sentence-transformers==2.2.2\n",
    "# !pip install InstructorEmbedding==1.0.1\n",
    "# #vectorstore\n",
    "# !pip install pymupdf==1.23.8\n",
    "# !pip install faiss-gpu==1.7.2\n",
    "# !pip install faiss-cpu==1.7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import langchain\n",
    "langchain.debug = True\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initiate our LLM \n",
    "# import torch\n",
    "\n",
    "# from transformers import (\n",
    "#     AutoTokenizer, \n",
    "#     AutoTokenizer, \n",
    "#     pipeline, \n",
    "#     AutoModelForSeq2SeqLM\n",
    "# )\n",
    "# from transformers import BitsAndBytesConfig\n",
    "# from langchain import HuggingFacePipeline\n",
    "\n",
    "# model_id = \"lmsys/fastchat-t5-3b-v1.0\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     model_id,\n",
    "# )\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# bitsandbyte_config = BitsAndBytesConfig(\n",
    "#         load_in_4bit = True,\n",
    "#         bnb_4bit_quant_type = \"nf4\",\n",
    "#         bnb_4bit_compute_dtype = torch.float16,\n",
    "#         bnb_4bit_use_double_quant = True\n",
    "#     )\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     quantization_config = bitsandbyte_config,\n",
    "#     device_map = 'auto',\n",
    "#     load_in_8bit = True,\n",
    "# )\n",
    "\n",
    "# pipe = pipeline(\n",
    "#     task=\"text2text-generation\", \n",
    "#     model=model, \n",
    "#     tokenizer=tokenizer, \n",
    "#     max_new_tokens=256, \n",
    "#     model_kwargs = { \n",
    "#         \"temperature\":0, \n",
    "#         \"repetition_penalty\": 1.5\n",
    "#     }, \n",
    "# )\n",
    "\n",
    "# llm = HuggingFacePipeline(pipeline = pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import OpenAI\n",
    "import openai\n",
    "import os\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "organization = os.getenv(\"OPEN_AI_ORG\")\n",
    "\n",
    "# Initiate our LLM - default is 'gpt-3.5-turbo'\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    api_key=api_key,\n",
    "    organization=organization\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Agent\n",
    "This is the chain responsible for deciding what step to take next. \n",
    "This is powered by a language model and a prompt. The inputs to this chain are:\n",
    "\n",
    "- `Tools`: Descriptions of available tools\n",
    "- `User input`: The high level objective\n",
    "- `Intermediate steps`: Any (action, tool output) pairs previously executed in order to achieve the user input\n",
    "The output is the next action(s) to take or the final response to send to the user (AgentActions or AgentFinish). An action specifies a tool and the input to that tool.\n",
    "\n",
    "Different agents have different prompting styles for reasoning, different ways of encoding inputs, and different ways of parsing the output. For a full list of built-in agents see agent types. You can also easily build custom agents, which we show how to do in the Get started section below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tools\n",
    "Tools are functions that an agent can invoke. There are two important design considerations around tools:\n",
    "1. Giving the agent access to the right tools\n",
    "2. Describing the tools in a way that is most helpful to the agent\n",
    "   \n",
    "Without thinking through both, you won't be able to build a working agent. If you don't give the agent access to a correct set of tools, it will never be able to accomplish the objectives you give it. If you don't describe the tools well, the agent won't know how to use them properly.\n",
    "\n",
    "LangChain provides a wide set of built-in tools, but also makes it easy to define your own (including custom descriptions). For a full list of built-in tools, see the [tools integrations section](https://python.langchain.com/docs/integrations/tools/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a Search tool \n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "search = WikipediaAPIWrapper()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "nlp_document = '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf'\n",
    "loader = PyMuPDFLoader(nlp_document)\n",
    "documents = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 700,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "docs = text_splitter.split_documents(documents) \n",
    "\n",
    "import torch\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "model_name = 'hkunlp/instructor-base'\n",
    "\n",
    "embedding_model = HuggingFaceInstructEmbeddings(\n",
    "        model_name = model_name,              \n",
    "        model_kwargs = {\n",
    "            'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        },\n",
    "    )\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_documents(docs, embedding_model)\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "nlp_retriever = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "# Define a list of tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]\n",
    "\n",
    "expanded_tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = 'Knowledge Base',\n",
    "        func=nlp_retriever.run,\n",
    "        description=\"Useful for general questions about how to do things and for details on interesting topics. Input should be a fully formed question.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template which can interpolate the history\n",
    "template_with_history = \"\"\"\n",
    "I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
    "If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
    "Whether it's about probabilistic models, language models, or any other related topic, \n",
    "I'm here to help break down complex concepts into easy-to-understand explanations.\n",
    "Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to give detailed, informative answers\n",
    "\n",
    "Previous conversation history:\n",
    "{history}\n",
    "\n",
    "New question: {input}\n",
    "{agent_scratchpad}\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import BaseChatPromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage, SystemMessage\n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "from typing import List, Union\n",
    "import zipfile\n",
    "\n",
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        \n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "            \n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        \n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        \n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [HumanMessage(content=formatted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_history = CustomPromptTemplate(\n",
    "    template=template_with_history,\n",
    "    tools=expanded_tools,\n",
    "    # The history template includes \"history\" as an input variable so we can interpolate it into the prompt\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"history\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \\nIf you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\nWhether it's about probabilistic models, language models, or any other related topic, \\nI'm here to help break down complex concepts into easy-to-understand explanations.\\nJust let me know what you're wondering about, and I'll do my best to guide you through it!\\nAnswer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Remember to give detailed, informative answers\\n\\nPrevious conversation history:\\n{history}\\n\\nNew question: {input}\\n{agent_scratchpad}\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_with_history.template"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ( \n",
    "    LLMSingleActionAgent, \n",
    "    AgentOutputParser\n",
    ")\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        \n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action: (.*?)[\\n]*Action Input:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        # If it can't parse the output it raises an error\n",
    "        # You can add your own logic here to handle errors in a different way i.e. pass to a human, give a canned response\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        \n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "    \n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMSingleActionAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import LLMSingleActionAgent\n",
    "from langchain import LLMChain\n",
    "\n",
    "# Re-initialize the agent with our new list of tools\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt_with_history)\n",
    "\n",
    "tool_names = [tool.name for tool in expanded_tools]\n",
    "\n",
    "multi_tool_agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# Initiate the agent that will respond to our queries\n",
    "# Set verbose=True to share the CoT reasoning the LLM goes through\n",
    "multi_tool_memory = ConversationBufferWindowMemory(k=2)\n",
    "multi_tool_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=multi_tool_agent, \n",
    "    tools=expanded_tools, \n",
    "    verbose=True, \n",
    "    memory=multi_tool_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "<re.Match object; span=(81, 153), match='Action: Knowledge Base\\nAction Input: \"What is th>\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Who are you by the way?\n",
      "Thought: The user is asking about my identity.\n",
      "Action: Knowledge Base\n",
      "Action Input: \"What is the identity of ChakyBot?\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3mBased on the given context, there is no information about a chatbot named \"ChakyBot.\" Therefore, I don't have any information about the identity of ChakyBot.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI don't have any information about the identity of ChakyBot.\n",
      "Final Answer: I am an NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am an NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP).'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_tool_executor.run(\"Who are you by the way?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "<re.Match object; span=(232, 295), match='Action: Knowledge Base\\nAction Input: What is the>\n",
      "\u001b[32;1m\u001b[1;3mThought: The Transformers is a powerful deep learning model architecture that has revolutionized the field of Natural Language Processing (NLP). It was introduced in the paper \"Attention is All You Need\" by Vaswani et al. in 2017.\n",
      "\n",
      "Action: Knowledge Base\n",
      "Action Input: What is the Transformers?\n",
      "\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3mThe Transformers are a type of neural network architecture that are used for sequence-to-sequence tasks, such as machine translation and natural language processing. They are made up of stacks of transformer blocks, which consist of simple linear layers, feedforward networks, and self-attention layers. The key innovation of transformers is the use of self-attention, which allows the network to extract and use information from arbitrarily large contexts without the need for recurrent connections. This makes transformers more efficient to implement at scale compared to other models.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe Transformers are a type of neural network architecture that are used for sequence-to-sequence tasks, such as machine translation and natural language processing. They are made up of stacks of transformer blocks, which consist of simple linear layers, feedforward networks, and self-attention layers. The key innovation of transformers is the use of self-attention, which allows the network to extract and use information from arbitrarily large contexts without the need for recurrent connections. This makes transformers more efficient to implement at scale compared to other models.\n",
      "\n",
      "Final Answer: The Transformers are a type of neural network architecture used for sequence-to-sequence tasks in NLP. They utilize self-attention to efficiently extract information from large contexts without the need for recurrent connections.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Transformers are a type of neural network architecture used for sequence-to-sequence tasks in NLP. They utilize self-attention to efficiently extract information from large contexts without the need for recurrent connections.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_tool_executor.run(\"What is the Transformers?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
