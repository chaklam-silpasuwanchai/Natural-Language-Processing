{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "composite-japanese",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Part 1: Introduction to SpaCy\n",
    "\n",
    "SpaCy is one of the top framework (alongside NLTK) for natural language processing.  On daily NLP tasks, you cannnot live without it.   Here we should explore different concepts such as (1) the philosophy of SpaCy, the (2) the concept of pipelines, (3) creating pipelines, and (4) visiting some interesting case studies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-movement",
   "metadata": {},
   "source": [
    "## 1. How to Install spaCy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "suburban-psychology",
   "metadata": {},
   "source": [
    "In order to install spaCy, I recommend visiting their website, here: https://spacy.io/usage\n",
    "\n",
    "If you are using pip, simply\n",
    "\n",
    "`pip install spacy` or `pip install -U 'spacy[cuda-autodetect]'`\n",
    "\n",
    "`python -m spacy download en_core_web_sm` \n",
    "\n",
    "`python -m spacy download en_core_web_md` \n",
    "\n",
    "For the `en_core_web_sm`, replace `sm` with `md` (medium), `lg` (large), and `trf` (transformers).  The more complex model you used, the better features you get."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-rating",
   "metadata": {},
   "source": [
    "Now that we've installed spaCy let's import it to make sure we installed it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "criminal-objective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-limit",
   "metadata": {},
   "source": [
    "Great! Now, let's make sure we downloaded the model successfully with the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "molecular-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-certification",
   "metadata": {},
   "source": [
    "Excellent! spaCy is now installed correctly and we have successfully downloaded the small English model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cellular-tender",
   "metadata": {},
   "source": [
    "## 2. Data structures\n",
    "\n",
    "Let's learn the data structures of spaCy.  The overarching container is the `Doc`, which contains a list of `Token` where a span of tokens creates a `Span`.  As you can see, things are very intuitive!.    There are much more stuffs but we are too lazy to understand them....we will slowly come across them.\n",
    "\n",
    "<img src = \"figures/container.svg\" width=\"300\">\n",
    "\n",
    "### The Doc object\n",
    "\n",
    "The Doc is one of the central data structures in spaCy. It's created automatically when you process a text with the nlp object. But you can also instantiate the class manually.\n",
    "\n",
    "After creating the nlp object, we can import the Doc class from spacy dot tokens.\n",
    "\n",
    "Here we're creating a Doc from three words. The spaces are a list of boolean values indicating whether the word is followed by a space. Every token includes that information – even the last one!\n",
    "\n",
    "The Doc class takes three arguments: the shared vocab, the words and the spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a02c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an nlp object\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "# Import the Doc class\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# The words and spaces to create the doc from\n",
    "words = ['Hello', 'world', '!']\n",
    "spaces = [True, False, False]\n",
    "\n",
    "# Create a doc manually\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "737b5a03",
   "metadata": {},
   "source": [
    "<img src = \"figures/span2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6541369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Doc and Span classes\n",
    "from spacy.tokens import Doc, Span\n",
    "\n",
    "# The words and spaces to create the doc from\n",
    "words = ['Hello', 'world', '!']\n",
    "spaces = [True, False, False]\n",
    "\n",
    "# Create a doc manually\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "\n",
    "# Create a span manually\n",
    "span = Span(doc, 0, 2)\n",
    "\n",
    "# Create a span with a label\n",
    "span_with_label = Span(doc, 0, 2, label=\"GREETING\")\n",
    "\n",
    "# Add span to the doc.ents\n",
    "doc.ents = [span_with_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa34c05b",
   "metadata": {},
   "source": [
    "## 3. Creating a Doc Container\n",
    "\n",
    "Great! With the model loaded, let's go ahead and import our text from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cfa0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"data/wiki_us.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef7294",
   "metadata": {},
   "source": [
    "Now, let's see what this text looks like. It can be a bit difficult to read in a JupyterBook, but notice the horizontal slider below. You don't neeed to read this in its entirety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82bff38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America. It consists of 50 states, a federal district, five major unincorporated territories, 326 Indian reservations, and some minor possessions.[j] At 3.8 million square miles (9.8 million square kilometers), it is the world's third- or fourth-largest country by total area.[d] The United States shares significant land borders with Canada to the north and Mexico to the south, as well as limited maritime borders with the Bahamas, Cuba, and Russia.[22] With a population of more than 331 million people, it is the third most populous country in the world. The national capital is Washington, D.C., and the most populous city is New York.\n"
     ]
    }
   ],
   "source": [
    "print (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ace8ab4",
   "metadata": {},
   "source": [
    "With the data loaded in, it's time to make our first Doc container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fde2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c31112f",
   "metadata": {},
   "source": [
    "Great! Let's see what this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba42c650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America. It consists of 50 states, a federal district, five major unincorporated territories, 326 Indian reservations, and some minor possessions.[j] At 3.8 million square miles (9.8 million square kilometers), it is the world's third- or fourth-largest country by total area.[d] The United States shares significant land borders with Canada to the north and Mexico to the south, as well as limited maritime borders with the Bahamas, Cuba, and Russia.[22] With a population of more than 331 million people, it is the third most populous country in the world. The national capital is Washington, D.C., and the most populous city is New York.\n"
     ]
    }
   ],
   "source": [
    "print (doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b51ed3b",
   "metadata": {},
   "source": [
    "**so what's the difference between raw text and doc?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ecfbbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n",
      "787\n"
     ]
    }
   ],
   "source": [
    "#the length is different, why?\n",
    "print (len(doc))\n",
    "print (len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca6622",
   "metadata": {},
   "source": [
    "Hmm... What's going on here? Same text, but different length. Why does this occur? To answer that, let's explore it more deeply and try and print off each item in each object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e29b4ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "h\n",
      "e\n",
      " \n",
      "U\n",
      "n\n",
      "i\n",
      "t\n",
      "e\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "for token in text[:10]:\n",
    "    print (token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3ed63",
   "metadata": {},
   "source": [
    "As we would expect. We have printed off each character, including white spaces. Let's try and do the same with the Doc container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf069c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "United\n",
      "States\n",
      "of\n",
      "America\n",
      "(\n",
      "U.S.A.\n",
      "or\n",
      "USA\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for token in doc[:10]:\n",
    "    print (token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33cd8b9",
   "metadata": {},
   "source": [
    "And now we see the magical difference. `Tokens` are created through the `en_core_web_sm`.   Another difference is the concept of `sents` which refer to sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b33324bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America.\n"
     ]
    }
   ],
   "source": [
    "sentence1 = list(doc.sents)[0]\n",
    "print (sentence1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd63b955",
   "metadata": {},
   "source": [
    "We can explore deeper into **token attributes** which hides many crazy good stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efb7d76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States\n"
     ]
    }
   ],
   "source": [
    "#let's pick a random token\n",
    "token2 = sentence1[2]\n",
    "print (token2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8ed99",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d995211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'States'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the raw text\n",
    "token2.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb975e",
   "metadata": {},
   "source": [
    "### Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2873c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#head of the dependency tree\n",
    "token2.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4dfe7",
   "metadata": {},
   "source": [
    "### Left Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a1c2873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this tell us where the multi-word token begins\n",
    "token2.left_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4623a5",
   "metadata": {},
   "source": [
    "### Right Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "829ce461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ","
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this will tell us where the multi-word token ends\n",
    "token2.right_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45cd04c",
   "metadata": {},
   "source": [
    "### Entity Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6626434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type of entity\n",
    "token2.ent_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ab578fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPE'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the actual name of the entity\n",
    "token2.ent_type_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbbe63ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('GPE') #geo political entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53716e",
   "metadata": {},
   "source": [
    "### Ent IOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de588305",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#“B” means the token begins an entity, “I” means it is inside an entity, \n",
    "# “O” means it is outside an entity, and \"\" means no entity tag is set.\n",
    "token2.ent_iob_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059501b",
   "metadata": {},
   "source": [
    "### Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b913b967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'know'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the root form of the word\n",
    "print(sentence1[12])\n",
    "sentence1[12].lemma_ #without _, it will give you an integer representation instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b1f20",
   "metadata": {},
   "source": [
    "### Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b2d2d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPN'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2.pos_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8064964e",
   "metadata": {},
   "source": [
    "### Syntactic Dependency\n",
    "\n",
    "<img src = \"figures/dep_example.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3819c6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nsubj'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2.dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f346a06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d3b91",
   "metadata": {},
   "source": [
    "### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd1cd8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2.lang_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "040ca8b9",
   "metadata": {},
   "source": [
    "### Boolean attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1125ffd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2.is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3cec709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2.is_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ed0ff29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2.like_email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd48e8",
   "metadata": {},
   "source": [
    "## 4. Part of Speech Tagging (POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29839c6",
   "metadata": {},
   "source": [
    "In the field of computational linguistics, understanding parts-of-speech is essential. SpaCy offers an easy way to parse a text and identify its parts of speech. Below, we will iterate across each token (word or punctuation) in the text and identify its part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b9fc292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Peter loves eating and Paris very much."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Peter loves eating and Paris very much.\")\n",
    "sentence1 = list(doc.sents)[0]\n",
    "sentence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcf61b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter PROPN nsubj\n",
      "loves VERB ROOT\n",
      "eating VERB xcomp\n",
      "and CCONJ cc\n",
      "Paris PROPN conj\n",
      "very ADV advmod\n",
      "much ADV advmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in sentence1:\n",
    "    print (token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be59158",
   "metadata": {},
   "source": [
    "Here, we can see two vital pieces of information: the string and the corresponding part-of-speech (pos). For a complete list of the pos labels, see the spaCy documentation (https://spacy.io/api/annotation#pos-tagging). Most of these, however, should be apparent, i.e. PROPN is proper noun, AUX is an auxiliary verb, ADJ, is adjective, etc. We can visualize this sentence with a diagram through spaCy's displaCy Notebook feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abb65796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4908861e0cdd401c8f1e60e15740545c-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Peter</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">loves</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">eating</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Paris</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">very</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">much.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4908861e0cdd401c8f1e60e15740545c-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4908861e0cdd401c8f1e60e15740545c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4908861e0cdd401c8f1e60e15740545c-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4908861e0cdd401c8f1e60e15740545c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4908861e0cdd401c8f1e60e15740545c-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4908861e0cdd401c8f1e60e15740545c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4908861e0cdd401c8f1e60e15740545c-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4908861e0cdd401c8f1e60e15740545c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4908861e0cdd401c8f1e60e15740545c-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4908861e0cdd401c8f1e60e15740545c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4908861e0cdd401c8f1e60e15740545c-0-5\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4908861e0cdd401c8f1e60e15740545c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,266.5 L1108.0,254.5 1092.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(sentence1, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b74feb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Berlin is a nice city\")\n",
    "\n",
    "# Iterate over the tokens\n",
    "for token in doc:\n",
    "    # Check if the current token is a proper noun\n",
    "    if token.pos_ == \"PROPN\":\n",
    "        # Check if the next token is a verb\n",
    "        if doc[token.i + 1].pos_ == \"VERB\":\n",
    "            print(\"Found proper noun before a verb:\", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96387b8",
   "metadata": {},
   "source": [
    "## 5. Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7bead0",
   "metadata": {},
   "source": [
    "Another essential task of NLP, is named entity recognition, or NER. SpaCy provides `doc.ents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39bc9f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin GPE\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a698d",
   "metadata": {},
   "source": [
    "We can use `displaCy` to display the text as NER annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8477103a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Berlin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is a nice city</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "valuable-accommodation",
   "metadata": {},
   "source": [
    "## 6. Word Vectors\n",
    "\n",
    "Let's explore word vectors a bit.  \n",
    "\n",
    "To do so, we shall use `en_core_web_md` which contains word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "developmental-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "with open (\"data/wiki_us.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "sentence1 = list(doc.sents)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8e2e4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "advance-porter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb1c4830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-7.2681 , -0.85717,  5.8105 ,  1.9771 ,  8.8147 ], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentence1[0].vector.shape)\n",
    "sentence1[0].vector[:5] #300 dimensions representing \"The\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "representative-intent",
   "metadata": {},
   "source": [
    "### Similarity\n",
    "\n",
    "<img src = \"figures/data-struct.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "340ca5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash value: 3197928453018144401\n",
      "string value: coffee\n"
     ]
    }
   ],
   "source": [
    "#before similarity, let's learn about nlp.vocab.strings\n",
    "doc = nlp(\"I love coffee\")\n",
    "print('hash value:', nlp.vocab.strings['coffee'])\n",
    "print('string value:', nlp.vocab.strings[3197928453018144401])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5588b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7562983679033046312"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first numercalize\n",
    "integer = nlp.vocab.strings['dog']\n",
    "integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e3b46ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.233 ,   4.2963,  -7.9738, -10.121 ,   1.8207], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's obtain the vector\n",
    "vector  = nlp.vocab.vectors[integer]\n",
    "vector[:5]  #too ugly to print all..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48ae4240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 7918624946109788756,  4969328240109515165,  4560869431627726864,\n",
       "         17429802345416193488,  6017664905485703127, 14534804554944721111,\n",
       "           173986088034745168, 15668852121853073894, 11567120971096873637,\n",
       "         15872191516786115817]], dtype=uint64),\n",
       " array([[ 1147,  2545,  3201,  9003,  3828, 18829,  5845, 11580,  7045,\n",
       "         18612]], dtype=int32),\n",
       " array([[1.    , 0.8334, 0.8221, 0.8108, 0.7856, 0.7195, 0.685 , 0.6328,\n",
       "         0.6148, 0.5966]], dtype=float32))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#obtain words that are most similar to this vector\n",
    "#need to put [] because most_similar accept numpy array of vectors\n",
    "close_words = nlp.vocab.vectors.most_similar(np.asarray([vector]), n=10)\n",
    "close_words  #vocab id,  (i don't know what is this...) , probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11418c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at only the vocab id (the first of the tuple)\n",
    "close_words[0].shape\n",
    "similar_vocabs = close_words[0].reshape(-1) #reshape of easy for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2d4d3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dogsbody',\n",
       " 'wolfdogs',\n",
       " 'Baeg',\n",
       " 'duppy',\n",
       " 'pet(s',\n",
       " 'postcanine',\n",
       " 'Kebira',\n",
       " 'uppies',\n",
       " 'Toropets',\n",
       " 'moggie']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [nlp.vocab.strings[word] for word in similar_vocabs]\n",
    "words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "accessory-framework",
   "metadata": {},
   "source": [
    "### Doc Similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "micro-virus",
   "metadata": {},
   "source": [
    "In spaCy we can do this same thing at the document level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "entire-anthony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.691649353055761\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
    "doc2 = nlp(\"Fast food tastes very good.\")\n",
    "\n",
    "# Similarity of two documents\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "serious-button",
   "metadata": {},
   "source": [
    "### Word Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-patrol",
   "metadata": {},
   "source": [
    "We can also calculate the similarity between two given words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "guided-spirituality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salty fries <-> hamburgers 0.6938489675521851\n"
     ]
    }
   ],
   "source": [
    "# Similarity of tokens and spans\n",
    "french_fries = doc1[2:4]\n",
    "burgers = doc1[5]\n",
    "print(french_fries, \"<->\", burgers, french_fries.similarity(burgers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a1cdc",
   "metadata": {},
   "source": [
    "### Span Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e12f4759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6348510384559631\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "doc = nlp(\"This was a great restaurant. Afterwards, we went to a really nice bar.\")\n",
    "\n",
    "# Create spans for \"great restaurant\" and \"really nice bar\"\n",
    "span1 = doc[3:5]\n",
    "span2 = doc[12:15]\n",
    "\n",
    "# Get the similarity of the spans\n",
    "similarity = span1.similarity(span2)\n",
    "print(similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('teaching_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "becc4c8e5ad229b2591d820334d85e3db0111492344629bf57f272470dce75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
