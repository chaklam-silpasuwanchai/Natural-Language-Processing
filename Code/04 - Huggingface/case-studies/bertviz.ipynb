{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inner Working\n",
    "\n",
    "- [Bertviz](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwiPqKGJi8WCAxV-amwGHTUACfsQFnoECA8QAQ&url=https%3A%2F%2Fgithub.com%2Fjessevig%2Fbertviz&usg=AOvVaw3ICdhqlIY9MEQVCogh41Yj&opi=89978449)\n",
    "- [Learning Interpretability Tool (LIT)](https://github.com/PAIR-code/lit)\n",
    "- [Ecco](https://github.com/jalammar/ecco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bertviz\n",
    "!pip install jupyterlab\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils\n",
    "from bertviz import model_view\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "\n",
    "model_name = \"microsoft/xtremedistil-l12-h384-uncased\"  # Find popular HuggingFace models here: https://huggingface.co/models\n",
    "input_text = \"The cat sat on the mat\"  \n",
    "model = AutoModel.from_pretrained(model_name, output_attentions=True)  # Configure model to return attention values\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
    "outputs = model(inputs)  # Run model\n",
    "attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
    "model_view(attention, tokens)  # Display model view"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-attention models (BERT, GPT-2, etc.)\n",
    "\n",
    "### Head and Model Views\n",
    "\n",
    "First load a Huggingface model, either a pre-trained model as shown below, or your own fine-tuned model. Be sure to set output_attentions=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\", output_attentions=True)\n",
    "\n",
    "inputs = tokenizer.encode(\"The cat sat on the mat\", return_tensors='pt')\n",
    "outputs = model(inputs)\n",
    "attention = outputs[-1]  # Output includes attention weights when output_attentions=True\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz import head_view\n",
    "head_view(attention, tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron View\n",
    "\n",
    "The neuron view is invoked differently than the head view or model view, due to requiring access to the model's query/key vectors, which are not returned through the Huggingface API. It is currently limited to custom versions of BERT, GPT-2, and RoBERTa included with BertViz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import specialized versions of models (that return query/key vectors)\n",
    "from bertviz.transformers_neuron_view import BertModel, BertTokenizer\n",
    "from bertviz.neuron_view import show\n",
    "\n",
    "model_type = 'bert'\n",
    "model_version = 'bert-base-uncased'\n",
    "do_lower_case = True\n",
    "sentence_a = \"The cat sat on the mat\"\n",
    "sentence_b = \"The cat lay on the rug\"\n",
    "model = BertModel.from_pretrained(model_version, output_attentions=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_version, do_lower_case=do_lower_case)\n",
    "show(model, model_type, tokenizer, sentence_a, sentence_b, layer=2, head=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-decoder models (BART, T5, etc.)\n",
    "\n",
    "The head view and model view both support encoder-decoder models.\n",
    "\n",
    "First, load an encoder-decoder model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
    "model = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\", output_attentions=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_ids = tokenizer(\"She sees the small elephant.\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    decoder_input_ids = tokenizer(\"Sie sieht den kleinen Elefanten.\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
    "\n",
    "outputs = model(input_ids=encoder_input_ids, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "encoder_text = tokenizer.convert_ids_to_tokens(encoder_input_ids[0])\n",
    "decoder_text = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz import model_view\n",
    "model_view(\n",
    "    encoder_attention=outputs.encoder_attentions,\n",
    "    decoder_attention=outputs.decoder_attentions,\n",
    "    cross_attention=outputs.cross_attentions,\n",
    "    encoder_tokens= encoder_text,\n",
    "    decoder_tokens = decoder_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizing sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz import head_view\n",
    "from transformers import AutoTokenizer, AutoModel, utils\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "\n",
    "# NOTE: This code is model-specific\n",
    "model_version = 'bert-base-uncased'\n",
    "model = AutoModel.from_pretrained(model_version, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_version)\n",
    "sentence_a = \"the rabbit quickly hopped\"\n",
    "sentence_b = \"The turtle slowly crawled\"\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
    "input_ids = inputs['input_ids']\n",
    "token_type_ids = inputs['token_type_ids'] # token type id is 0 for Sentence A and 1 for Sentence B\n",
    "attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
    "sentence_b_start = token_type_ids[0].tolist().index(1) # Sentence B starts at first index of token type id 1\n",
    "token_ids = input_ids[0].tolist() # Batch index 0\n",
    "tokens = tokenizer.convert_ids_to_tokens(token_ids)    \n",
    "head_view(attention, tokens, sentence_b_start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encourage To Read\n",
    "- [The elephant in the interpretability room:Why use attention as explanation when we have saliency methods?](https://arxiv.org/pdf/2010.05607.pdf)\n",
    " - [What Does BERT Look At? An Analysis of BERT's Attention](https://arxiv.org/pdf/1906.04341.pdf)\n",
    " - [Visualizing and Understanding Recurrent Networks](https://arxiv.org/pdf/1506.02078.pdf)\n",
    " - [Improving Transformer Models by Reordering their Sublayers](https://arxiv.org/pdf/1911.03864.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
