{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ad55e6-9d4c-43fd-a5ad-3dd6a9f9c8c7",
   "metadata": {},
   "source": [
    "# Token Classification (HuggingFace)\n",
    "\n",
    "- NER, POS Tagging, Chunking (which tokens belong to the same entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8aa15f-5a16-4a36-a232-df4f025e5a9a",
   "metadata": {},
   "source": [
    "## 1. Load the data\n",
    "\n",
    "CoNLL-2003 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d8341a-38a8-4f09-b022-68a028dfe8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "120a0a04-add2-478d-b48a-f57713016bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/home/chaklams/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3b97c352944fb4874d1170bf939ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83adee20-7027-4b35-ad03-ab3f63a3d1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54723610-c042-435b-b0b1-2f10f7c03fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9334a2b1-a3ac-4409-9307-45c5a80aa43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe020ea-410f-4405-8585-8380bfb06c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 42, 16, 21, 35, 37, 16, 21, 7]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"pos_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89542e59-3ff0-439a-a66e-db4cf21a9983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"].features[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c7c4e0-3bea-4abe-b9c8-8053a0c81e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"].features[\"pos_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdfe4444-6e73-46f0-8dd1-2ae20305dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_features = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "label_names  = ner_features.feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459fbb3d-e1f1-4b46-af47-249830e74b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e74043-e1e4-46a7-940a-b1ddd759cc30",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "Tokenization (numericalization), aligning labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2e01488-6ce8-4f48-9533-733e20823401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfa894ef-03bf-4a57-b5f3-dc14fffbd504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 24705, 3781, 7871, 1996, 3776, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Chaky loves deep learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "196841a9-fa21-48b4-9b3b-81ba5e0a97db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Chaky loves deep learning [SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([101, 24705, 3781, 7871, 1996, 3776, 102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcdbc4ae-f722-4cb6-85fe-23f75538986d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast #basically a internal Huggingface\n",
    "#optimization that makes its tokenizer very fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f8d0a0-d18c-4d89-93ee-cbfd38c36ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = raw_datasets[\"train\"][0][\"tokens\"]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d620ea7b-386a-4d78-a63a-d490d2f13fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we have to aware that our inputs are already\n",
    "#tokenized.....\n",
    "\n",
    "inputs = tokenizer(tokens, is_split_into_words=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e3030de-afc3-4522-b1db-d3e323d69776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'EU',\n",
       " 'rejects',\n",
       " 'German',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'British',\n",
       " 'la',\n",
       " '##mb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f89630e-d72e-47de-8377-b46f3e6dcce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf35bb01-b67a-4f24-a6c6-a9a30478412e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5299602-97d9-4c67-aac0-6e9ef31c1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    \n",
    "    for word_id in word_ids:\n",
    "        \n",
    "        if word_id != current_word:\n",
    "            #Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        \n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100) #-100 is a default index to ignore for huggingface\n",
    "            \n",
    "        else:\n",
    "            #same word as previous token\n",
    "            label = labels[word_id]\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "            \n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9f39ef6-c5f6-45fb-a5a4-893ab30962be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f012355-798d-4a05-8841-923ada1326b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    \n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6e0e97e-d3a7-4556-9035-8149b62efb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/chaklams/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-d092dc72a12920cb.arrow\n",
      "Loading cached processed dataset at /home/chaklams/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-c1b68a354bc3153d.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9ac694e9a740ab9a6ee401be8cafc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels, batched=True, remove_columns=raw_datasets[\"train\"].column_names,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c003a623-ddda-4998-a6c0-4425c83b8f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9cf0feb-d1b6-49ba-bc3b-873b11920454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a420e063-626a-4ab2-9914-adff0298a914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] EU rejects German call to boycott British lamb. [SEP]'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_datasets[\"train\"][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23d0a7d3-42db-4ac7-9ca7-97ec77c99135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d095a3d0-dc5a-4e76-98af-d5316f5040fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a16d0164-1ae4-4314-aacf-f6f833b2ff78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bda154b-ea07-42ca-b18a-c3febf66ee73",
   "metadata": {},
   "source": [
    "## 3. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c92406ec-a1f4-4c69-ba74-e30baf7b725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "#huggingface is very kind to make a data collator for each pipeline\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "006102aa-1122-4282-a4a6-2e7a635fe49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [tokenized_datasets[\"train\"][i] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8829ffa-5c80-4645-b985-827bf368d783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7270, 22961,  1528,  1840,  1106, 21423,  1418,  2495, 12913,\n",
       "            119,   102],\n",
       "         [  101,  1943, 14428,   102,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'labels': tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
       "         [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9adb3a6-eecf-41ca-aa41-5a02a494dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(tokenized_datasets[\"train\"],      shuffle=True,\n",
    "                          collate_fn=data_collator, batch_size=8)\n",
    "val_loader   = DataLoader(tokenized_datasets[\"validation\"],\n",
    "                          collate_fn=data_collator, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "861fb952-b9c6-451f-a8dd-62a8d2d23d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_loader:\n",
    "#     print(batch)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879bb709-fbea-4aa6-a8be-b8d82e03165a",
   "metadata": {},
   "source": [
    "## 4. Model\n",
    "\n",
    "The second part of the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31155fee-f665-443c-b79c-be8c576741ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {str(i): label for i, label in enumerate(label_names)}\n",
    "label2id = {v:k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ed9b7d3-1242-401f-961b-55a551597830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "#basically, it imports a pretrained model, and add linear layers and only train that layers....\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint, id2label=id2label,label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be220231-4b5a-4784-8322-670c12d6194f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508fe5ce-07d0-4b7a-abd2-869c88eb18d3",
   "metadata": {},
   "source": [
    "## 5. Metrics\n",
    "\n",
    "We need to define `compute_metrics()` that takes list of predictions and labels, and returns \n",
    "a dictionary with the metric names and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b2ac850-e8d0-4825-89cb-085415add5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c949487-cc3a-43e1-9a39-0e655acfb6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72cd06ff-1661-45ed-afaf-a5690aa5ffeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9125fee1-6008-4d20-bc61-bdeb080d6be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label_names[i] for i in labels]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76ec6fa7-1640-4069-9829-6617b2951313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metric.compute\n",
    "#let's create a fake label by perturbing the label by changing some value, at index 2\n",
    "pred = labels.copy()\n",
    "pred[2] = 'B-ORG'\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79b55804-1120-4fe1-9351-8bb47a0465f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric.compute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b32bb7fb-492e-46ac-be79-3de541bf3313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MISC': {'precision': 1.0,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 2},\n",
       " 'ORG': {'precision': 0.5,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 1},\n",
       " 'overall_precision': 0.6666666666666666,\n",
       " 'overall_recall': 0.6666666666666666,\n",
       " 'overall_f1': 0.6666666666666666,\n",
       " 'overall_accuracy': 0.8888888888888888}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=[pred], references=[labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648605a1-e3b8-46cb-99a7-6333e58e9954",
   "metadata": {},
   "source": [
    "## 6. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f57d2628-2e01-402f-bee5-6bb70760ccb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2e-05"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90363a22-adde-4ea2-8cf5-8b837c0b733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "#Adam with learning decay\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972e8a3-ecac-4129-94b8-1ab61fd722f6",
   "metadata": {},
   "source": [
    "## 7. Accelerator\n",
    "\n",
    "So usually, you just train right..\n",
    "\n",
    "But huggingface creates a wrapper called `Accelerator` which\n",
    "utilize your resources in a parallel fashion...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b624dfe-82c6-48cb-b365-620cd540997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8fd2b28-3001-486b-a91c-cd3137bdc974",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "\n",
    "model, optimizer, train_loader, val_loader = \\\n",
    "    accelerator.prepare(model, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f1558-2929-4305-9796-512531cf61ef",
   "metadata": {},
   "source": [
    "## 8. Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35dbf2b1-60b4-4cda-8143-f2b999a4e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 1\n",
    "num_update_steps_per_epoch = len(train_loader)\n",
    "num_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede399a5-168b-4719-bb85-7a49aaca1867",
   "metadata": {},
   "source": [
    "## 9. Repository\n",
    "\n",
    "Repository is like a free-cloud space, hosted by HuggingFace.\n",
    "\n",
    "It is very useful because for every certain steps, it will upload\n",
    "your model to the Huggingface....if suddenly something crashes, \n",
    "you can resume....because your weights are push to Huggingface repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cfa0c60e-c664-4b74-ba7e-ae9b100af037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29785c5502204d64bc93dc66bebca713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "420cd6d9-ae73-42a0-8142-db81e0450db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chaklam/bert-finetuned-ner-accelerate'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import Repository, get_full_repo_name\n",
    "\n",
    "model_name = \"bert-finetuned-ner-accelerate\"\n",
    "repo_name  = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f4a4484-87a8-4367-a17c-5d756ddf1531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaklams/NLP/Huggingface/Case studies/bert-finetuned-ner-accelerate is already a clone of https://huggingface.co/Chaklam/bert-finetuned-ner-accelerate. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "#sudo apt install git-lfs\n",
    "#sudo brew install git-lfs\n",
    "#go to git-lfs and download it\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "output_dir = \"bert-finetuned-ner-accelerate\"\n",
    "repo       = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d5ce8-103b-4970-b180-11d80246f641",
   "metadata": {},
   "source": [
    "## 10. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "70200178-5bb8-4176-ada7-aa24ead70ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert predictions and labels into strings, like \n",
    "#what our metric object expects\n",
    "\n",
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels      = labels.detach().cpu().clone().numpy()\n",
    "    \n",
    "    true_labels = [[label_names[l] for l in label if l !=-100] \n",
    "                   for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l!= - 100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4424de47-a2ac-48c5-adb1-11b851c07181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9861c7ddd7ce4228bb0ab5e65a2f558c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:  {'precision': 0.9288118478626725, 'recall': 0.8915993537964458, 'f1': 0.9098252555225849, 'accuracy': 0.9817360334373344}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm #progress bar\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_train_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        outputs = model(**batch) #** because our input is keyword (input_ids = ...)\n",
    "        loss    = outputs.loss\n",
    "        accelerator.backward(loss)  #instead of optimizer.backward\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    #evaluation\n",
    "    model.eval() #all batchnorm, dropout will be turned off....\n",
    "    for batch in val_loader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch) \n",
    "        \n",
    "        predictions = outputs.logits.argmax(dim = -1)\n",
    "        labels      = batch[\"labels\"]\n",
    "        \n",
    "        #necessary to pad predictions and labels to same length...if not...crash...\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels      = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "        \n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered      = accelerator.gather(labels)\n",
    "        \n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "        \n",
    "    results = metric.compute()\n",
    "\n",
    "    print(\n",
    "\n",
    "        f\"epoch {epoch}: \",\n",
    "        {\n",
    "                key: results[f\"overall_{key}\"]\n",
    "                for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "        }\n",
    "\n",
    "    )\n",
    "        \n",
    "    #save and upload your model\n",
    "    accelerator.wait_for_everyone() #many processes\n",
    "    unwrapped_model = accelerator.unwrap_model(model) #start from scratch\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    \n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        repo.push_to_hub(commit_message=f\"Training in progress epoch {epoch}\", blocking=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f58051-f2f2-4c5b-a99a-098d2b015aa1",
   "metadata": {},
   "source": [
    "## 11. Inference!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d0bf06d-50d4-4042-afbe-8dcdebd55c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "checkpoint = \"Chaklam/bert-finetuned-ner-accelerate\"\n",
    "\n",
    "clf        = pipeline(\"token-classification\", model=checkpoint, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c861e278-30a8-4162-95a9-c1458ceefa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.95654994,\n",
       "  'word': 'Ayush',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.96599174,\n",
       "  'word': 'Chaklam',\n",
       "  'start': 10,\n",
       "  'end': 17},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.66458696,\n",
       "  'word': 'AIT',\n",
       "  'start': 52,\n",
       "  'end': 55},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9953726,\n",
       "  'word': 'Bangkok',\n",
       "  'start': 57,\n",
       "  'end': 64},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9966755,\n",
       "  'word': 'Thailand',\n",
       "  'start': 66,\n",
       "  'end': 74}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(\"Ayush and Chaklam are going to play soccer today at AIT, Bangkok, Thailand and each some snacks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
