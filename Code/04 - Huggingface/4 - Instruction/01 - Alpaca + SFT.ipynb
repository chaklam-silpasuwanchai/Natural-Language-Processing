{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d8b2f91-c5e9-42e5-a23e-e21237e8b649",
   "metadata": {},
   "source": [
    "# Instruction Tuning\n",
    "This module will guide you through instruction tuning language models. Instruction tuning involves adapting pre-trained models to specific tasks by further training them on task-specific datasets. This process helps models improve their performance on targeted tasks.\n",
    "\n",
    "In this module, we will explore two topics: 1) Alpaca Prompt Template and 2) SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dc3f7a6-1e9c-4db3-a6fe-670d84c03b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "#uncomment this if you are not using our department puffer\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6302c696-6f58-4a9d-8a00-3a923ac76fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcccf64-a981-495b-abcc-b58f5a552f9b",
   "metadata": {},
   "source": [
    "## Dataset format support\n",
    "The SFTTrainer supports popular dataset formats. This allows you to pass the dataset to the trainer without any pre-processing directly. The following formats are supported:\n",
    "\n",
    "instruction format \n",
    "```sh\n",
    "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "\n",
    "```\n",
    "\n",
    "conversational format\n",
    "```sh\n",
    "{\"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are helpful\"}, \n",
    "    {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"...\"}\n",
    "]},\n",
    "{\"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are helpful\"}, \n",
    "    {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"...\"}\n",
    "]}, \n",
    "{\"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are helpful\"}, \n",
    "    {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"...\"}\n",
    "]}\n",
    "```\n",
    "\n",
    "If your dataset uses one of the above formats, you can directly pass it to the trainer without pre-processing. The SFTTrainer will then format the dataset for you using the defined format from the modelâ€™s tokenizer with the apply_chat_template method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a25633e-d4e5-4715-97fa-a49c524b7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "model = model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Set our name for the finetune to be saved &/ uploaded to\n",
    "finetune_name = \"SmolLM2-FT-MyDataset\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0179773-8d19-4949-bc4d-cd4b11d91fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 20022\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load the dataset\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"lucasmccabe-lmi/CodeAlpaca-20k\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ae473d-7bd2-45cf-9f65-7bc5901dc4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Create a function that takes a specific input and produces a specific output using any mathematical operators. Write corresponding code in Python.',\n",
       " 'input': '',\n",
       " 'output': 'def f(x):\\n    \"\"\"\\n    Takes a specific input and produces a specific output using any mathematical operators\\n    \"\"\"\\n    return x**2 + 3*x'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecadbb35-ae92-456c-b6a9-fd58d8acc26d",
   "metadata": {},
   "source": [
    "### Standard-Alpaca : Format your input prompts\n",
    "For instruction fine-tuning, it is quite common to have two columns inside the dataset: one for the prompt & the other for the response.\n",
    "\n",
    "This allows people to format examples like [Stanford-Alpaca](https://github.com/tatsu-lab/stanford_alpaca) did as follows:\n",
    "\n",
    "```sh\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "{response}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b62f5b8-363e-483f-8742-4916d1ad5c92",
   "metadata": {},
   "source": [
    "**Customize your prompts using packed dataset**\n",
    "\n",
    "If your dataset has several fields that you want to combine, for example if the dataset has question and answer fields and you want to combine them, you can pass a formatting function to the trainer that will take care of that. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2794592a-5240-4e01-9c17-81bff6899ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Question: Create a function that takes a specific input and produces a specific output using any mathematical operators. Write corresponding code in Python.\\n ### Answer: def f(x):\\n    \"\"\"\\n    Takes a specific input and produces a specific output using any mathematical operators\\n    \"\"\"\\n    return x**2 + 3*x'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['instruction']}\\n ### Answer: {example['output']}\"\n",
    "    return text\n",
    "\n",
    "formatting_func(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b81f3233-64af-4b18-986d-2b4b8badf65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The `formatting_func` should return a list of processed strings since it can lead to silent bugs.\n",
    "    \n",
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        text = f\"### Question: {example['instruction'][i]}\\n ### Answer: {example['output'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f96fdebf-dac2-4d32-ab2c-4fa64a280444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3571377/29572328.py:23: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n"
     ]
    }
   ],
   "source": [
    "response_template = \" ### Answer:\"\n",
    "\n",
    "collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template, tokenizer=tokenizer)\n",
    "\n",
    "# Step 3.1 : Set configure the SFTTrainer\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./sft_alpaca\",\n",
    "    max_steps=1000,  # Adjust based on dataset size and desired training duration\n",
    "    per_device_train_batch_size=4,  # Set according to your GPU memory capacity\n",
    "    learning_rate=5e-5,  # Common starting point for fine-tuning\n",
    "    logging_steps=100,  # Frequency of logging training metrics\n",
    "    save_steps=500,  # Frequency of saving model checkpoints\n",
    "    # evaluation_strategy=\"steps\",  # Evaluate the model at regular intervals\n",
    "    # eval_steps=50,  # Frequency of evaluation\n",
    "    use_mps_device=(\n",
    "        True if device == \"mps\" else False\n",
    "    ),  # Use MPS for mixed precision training\n",
    "    hub_model_id=finetune_name,  # Set a unique name for your model\n",
    ")\n",
    "\n",
    "# Step 3.2 : Initialize the SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,  # The pre-trained model to be fine-tuned\n",
    "    args=sft_config,  # Configuration settings for fine-tuning, such as training steps and batch size\n",
    "    formatting_func=formatting_prompts_func,  # Function to format input prompts for the model\n",
    "    train_dataset=dataset[\"train\"],  # Training dataset used for fine-tuning\n",
    "    data_collator=collator,  # Handles batch collation and response formatting\n",
    "    tokenizer=tokenizer,  # Tokenizer used for text processing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f13688a-618d-44f0-bece-010a5fd5332d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 04:13, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.907400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.921400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.835500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.849600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.783800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.839800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.822900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.826900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.751400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.756000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.8294741744995118, metrics={'train_runtime': 253.7607, 'train_samples_per_second': 15.763, 'train_steps_per_second': 3.941, 'total_flos': 394352973563904.0, 'train_loss': 0.8294741744995118, 'epoch': 0.1997602876548142})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000c76d-2037-4d4e-87eb-6ab16a63aeff",
   "metadata": {},
   "source": [
    "### Test the fine-tuned model on the same prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff3edd45-5b63-4284-888d-143cfb1d7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model_name = \"./sft_alpaca/checkpoint-1000\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77ef5be4-cc6d-42bd-a134-c235d9859aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'When did Virgin Australia start operating?',\n",
       " 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\",\n",
       " 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.',\n",
       " 'category': 'closed_qa'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset \n",
    "sample = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50c123a5-760f-42c5-a0c3-6f6ace0c83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['instruction']}\\n ### Answer:\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3977627-492c-4be9-8277-0971b228e101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Generate response\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(device)\n",
    "input_ids = tokenizer(formatting_func(sample[0]), return_tensors=\"pt\", truncation=True).input_ids.to(device)\n",
    "# with torch.inference_mode():\n",
    "outputs = model.generate(input_ids=input_ids, max_new_tokens=100, do_sample=True, top_p=0.9,temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ebd0298-006d-4d13-a146-3761b9ae892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "When did Virgin Australia start operating?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prompt:\\n{sample[0]['instruction']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "919c342b-b401-4b34-8cc1-9407efeb0ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated instruction:\n",
      "il Service, and the Australian Air Mail service, was made in August 1929. This was the first manned flight between the two nations. The first passenger flight between the two nations, between Brisbane and Sydney, was made in 1930. This is when the first commercial flights between the two nations were made. The first flights\n"
     ]
    }
   ],
   "source": [
    "print(f\"Generated instruction:\\n{tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d777b18e-101d-4f99-8692-e7e7ffe494a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth:\n",
      "Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ground truth:\\n{sample[0]['response']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0729ad1c-b863-4151-8dd2-e97ed85ade7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 538.06 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory footprint: {model.get_memory_footprint() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbc513f-14f4-420b-807a-573f24f7bf13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
