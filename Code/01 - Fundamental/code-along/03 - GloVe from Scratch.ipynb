{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GloVE\n",
        "\n",
        "Let's work on implementation of GloVE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\",\n",
        "                 \"dog cat animal\", \"cat animal dog\", \"cat dog animal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'animal', 'dog'],\n",
              " ['cat', 'dog', 'animal']]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = [sent.split(\" \") for sent in corpus]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'cat', 'fruit', 'banana', 'animal', 'dog']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'apple': 0, 'cat': 1, 'fruit': 2, 'banana': 3, 'animal': 4, 'dog': 5}\n"
          ]
        }
      ],
      "source": [
        "#numericalization\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "print(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "#vocab size\n",
        "voc_size = len(vocab)\n",
        "print(voc_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#append UNK\n",
        "vocab.append('<UNK>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'cat', 'fruit', 'banana', 'animal', 'dog', '<UNK>']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2index['<UNK>'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#just in case we need to use\n",
        "index2word = {v:k for k, v in word2index.items()} "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build Co-occurence Matrix X"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we need to count the co-occurence of two words given some window size.  We gonna use window size of 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'apple': 3, 'banana': 3, 'fruit': 3, 'dog': 3, 'cat': 3, 'animal': 3})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "X_i = Counter(flatten(corpus))\n",
        "X_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('banana', 'apple'),\n",
              " ('banana', 'fruit'),\n",
              " ('apple', 'banana'),\n",
              " ('apple', 'fruit'),\n",
              " ('fruit', 'banana'),\n",
              " ('fruit', 'apple'),\n",
              " ('cat', 'dog'),\n",
              " ('cat', 'animal'),\n",
              " ('animal', 'cat'),\n",
              " ('animal', 'dog'),\n",
              " ('dog', 'cat'),\n",
              " ('dog', 'animal')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skip_grams = []\n",
        "\n",
        "for doc in corpus:\n",
        "    for i in range(1, len(doc)-1):\n",
        "        center = doc[i]\n",
        "        outside = [doc[i-1], doc[i+1]]\n",
        "        for each_out in outside:\n",
        "            skip_grams.append((center, each_out))\n",
        "skip_grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({('banana', 'apple'): 1,\n",
              "         ('banana', 'fruit'): 1,\n",
              "         ('apple', 'banana'): 1,\n",
              "         ('apple', 'fruit'): 1,\n",
              "         ('fruit', 'banana'): 1,\n",
              "         ('fruit', 'apple'): 1,\n",
              "         ('cat', 'dog'): 1,\n",
              "         ('cat', 'animal'): 1,\n",
              "         ('animal', 'cat'): 1,\n",
              "         ('animal', 'dog'): 1,\n",
              "         ('dog', 'cat'): 1,\n",
              "         ('dog', 'animal'): 1})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_ik_skipgrams = Counter(skip_grams)\n",
        "X_ik_skipgrams"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Weighting function\n",
        "\n",
        "GloVe includes a weighting function to scale down too frequent words.\n",
        "\n",
        "<img src = \"../figures/glove_weighting_func.png\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighting(w_i, w_j, X_ik):\n",
        "    \n",
        "    #check whether the co-occurences between w_i and w_j is available\n",
        "    try:\n",
        "        x_ij = X_ik[(w_i, w_j)]\n",
        "        #if not exist, then set to 1 \"laplace smoothing\"\n",
        "    except:\n",
        "        x_ij = 1\n",
        "        \n",
        "    #set xmax\n",
        "    x_max = 100\n",
        "    #set alpha\n",
        "    alpha = 0.75\n",
        "    \n",
        "    #if co-ocurrence does not exceeed xmax, then just multiply with some alpha\n",
        "    if x_ij < x_max:\n",
        "        result = (x_ij / x_max)**alpha\n",
        "    #otherwise, set to 1\n",
        "    else:\n",
        "        result = 1\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import combinations_with_replacement\n",
        "\n",
        "X_ik = {} #keeping the co-occurences\n",
        "weighting_dic = {} #already scale the co-occurences using the weighting function\n",
        "\n",
        "for bigram in combinations_with_replacement(vocab, 2):\n",
        "    if X_ik_skipgrams.get(bigram):  #if the pair exists in our corpus\n",
        "        co = X_ik_skipgrams[bigram]\n",
        "        X_ik[bigram] = co + 1 #for stability\n",
        "        X_ik[(bigram[1], bigram[0])] = co + 1 #basically apple, banana = banana, apple\n",
        "    else:\n",
        "        pass\n",
        "    \n",
        "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
        "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Prepare train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
        "    \n",
        "    random_inputs, random_labels, random_coocs, random_weightings = [], [], [], []\n",
        "    \n",
        "    #convert our skipgrams to id\n",
        "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
        "    \n",
        "    #randomly choose indexes based on batch size\n",
        "    random_index = np.random.choice(range(len(skip_grams_id)), batch_size, replace=False)\n",
        "    \n",
        "    #get the random input and labels\n",
        "    for index in random_index:\n",
        "        random_inputs.append([skip_grams_id[index][0]])\n",
        "        random_labels.append([skip_grams_id[index][1]])\n",
        "        #coocs\n",
        "        pair = skip_grams[index] #e.g., ('banana', 'fruit')\n",
        "        try:\n",
        "            cooc = X_ik[pair]\n",
        "        except:\n",
        "            cooc = 1\n",
        "        random_coocs.append([math.log(cooc)])\n",
        "    \n",
        "        #weightings\n",
        "        weighting = weighting_dic[pair]\n",
        "        random_weightings.append([weighting])\n",
        "        \n",
        "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weightings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "x, y, cooc, weighting = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [2]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[5],\n",
              "       [0]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.69314718],\n",
              "       [0.69314718]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cooc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.05318296],\n",
              "       [0.05318296]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weighting"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model\n",
        "\n",
        "<img src =\"../figures/glove.png\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Glove(nn.Module):\n",
        "    \n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(Glove, self).__init__()\n",
        "        self.center_embedding  = nn.Embedding(voc_size, emb_size)\n",
        "        self.outside_embedding = nn.Embedding(voc_size, emb_size)\n",
        "        \n",
        "        self.center_bias       = nn.Embedding(voc_size, 1) \n",
        "        self.outside_bias      = nn.Embedding(voc_size, 1)\n",
        "    \n",
        "    def forward(self, center, outside, coocs, weighting):\n",
        "        center_embeds  = self.center_embedding(center) #(batch_size, 1, emb_size)\n",
        "        outside_embeds = self.outside_embedding(outside) #(batch_size, 1, emb_size)\n",
        "        \n",
        "        center_bias    = self.center_bias(center).squeeze(1)\n",
        "        target_bias    = self.outside_bias(outside).squeeze(1)\n",
        "        \n",
        "        inner_product  = outside_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) = (batch_size, 1)\n",
        "        \n",
        "        loss = weighting * torch.pow(inner_product + center_bias + target_bias - coocs, 2)\n",
        "        \n",
        "        return torch.sum(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "#test our system\n",
        "voc_size = len(vocab)\n",
        "emb_size = 2\n",
        "model = Glove(voc_size, emb_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_tensor = torch.LongTensor(x)\n",
        "y_tensor = torch.LongTensor(y)\n",
        "cooc_tensor = torch.FloatTensor(cooc)\n",
        "weighting_tensor = torch.FloatTensor(weighting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss = model(x_tensor, y_tensor, cooc_tensor, weighting_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.0150, grad_fn=<SumBackward0>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size     = 10 # mini-batch size\n",
        "embedding_size = 2 #so we can later plot\n",
        "model          = Glove(voc_size, embedding_size)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000 | cost: 0.129271 | time: 0m 0s\n",
            "Epoch: 2000 | cost: 0.000088 | time: 0m 0s\n",
            "Epoch: 3000 | cost: 0.000000 | time: 0m 0s\n",
            "Epoch: 4000 | cost: 0.000000 | time: 0m 0s\n",
            "Epoch: 5000 | cost: 0.000000 | time: 0m 0s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "    input_batch  = torch.LongTensor(input_batch)         #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch)        #[batch_size, 1]\n",
        "    cooc_batch   = torch.FloatTensor(cooc_batch)         #[batch_size, 1]\n",
        "    weighting_batch = torch.FloatTensor(weighting_batch) #[batch_size, 1]\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = model(input_batch, target_batch, cooc_batch, weighting_batch)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Plotting the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'cat', 'fruit', 'banana', 'animal', 'dog', '<UNK>']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#list of vocabs\n",
        "vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "word = vocab[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#numericalization\n",
        "id = word2index[word]\n",
        "id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_tensor = torch.LongTensor([id])\n",
        "id_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.5743, -0.6562]], grad_fn=<EmbeddingBackward0>),\n",
              " tensor([[0.1942, 0.8031]], grad_fn=<EmbeddingBackward0>))"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get the embedding by averaging\n",
        "v_embed = model.center_embedding(id_tensor)\n",
        "u_embed = model.outside_embedding(id_tensor)\n",
        "\n",
        "v_embed, u_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3843, 0.0734]], grad_fn=<DivBackward0>)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#average to get the word embedding\n",
        "word_embed = (v_embed + u_embed) / 2\n",
        "word_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's write a function to get embedding given a word\n",
        "def get_embed(word):\n",
        "    id_tensor = torch.LongTensor([word2index[word]])\n",
        "    v_embed = model.center_embedding(id_tensor)\n",
        "    u_embed = model.outside_embedding(id_tensor) \n",
        "    word_embed = (v_embed + u_embed) / 2 \n",
        "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocab[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Cosine similarity\n",
        "\n",
        "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
        "\n",
        "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
        "\n",
        "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'cat', 'fruit', 'banana', 'animal', 'dog', '<UNK>']"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's try similarity between first and second, and second and third\n",
        "cat          = get_embed('cat')\n",
        "fruit        = get_embed('fruit')\n",
        "animal       = get_embed('animal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  0.07236174001427882\n",
            "cat vs. animal:  0.747020177091881\n",
            "cat vs. cat:  1.0000000000000002\n"
          ]
        }
      ],
      "source": [
        "#numpy version\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "    \n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  0.07236174001427886\n",
            "cat vs. animal:  0.747020177091881\n",
            "cat vs. cat:  1\n"
          ]
        }
      ],
      "source": [
        "#scipy version\n",
        "from scipy import spatial\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n",
        "    return cos_sim\n",
        "\n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "dsai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
