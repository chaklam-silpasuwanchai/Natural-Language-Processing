{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Natural Language Processing\n",
        "\n",
        "## Word2Vec (Negative Sampling)\n",
        "\n",
        "Let's work on negative-sampling based implementation of word2vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Define some very simple data for understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\",\n",
        "                 \"dog cat animal\", \"cat animal dog\", \"cat dog animal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'animal', 'dog'],\n",
              " ['cat', 'dog', 'animal']]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = [sent.split(\" \") for sent in corpus]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'dog', 'banana', 'cat', 'fruit', 'animal']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'apple': 0, 'dog': 1, 'banana': 2, 'cat': 3, 'fruit': 4, 'animal': 5}\n"
          ]
        }
      ],
      "source": [
        "#numericalization\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "print(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "#vocab size\n",
        "voc_size = len(vocab)\n",
        "print(voc_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#append UNK\n",
        "vocab.append('<UNK>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'dog', 'banana', 'cat', 'fruit', 'animal', '<UNK>']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2index['<UNK>'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#just in case we need to use\n",
        "index2word = {v:k for k, v in word2index.items()} "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'fruit']\n",
            "['banana', 'apple', 'fruit']\n",
            "['banana', 'fruit', 'apple']\n",
            "['dog', 'cat', 'animal']\n",
            "['cat', 'animal', 'dog']\n",
            "['cat', 'dog', 'animal']\n"
          ]
        }
      ],
      "source": [
        "for c in corpus:\n",
        "    print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_batch(batch_size, word_sequence):\n",
        "    \n",
        "    # Make skip gram of one size window\n",
        "    skip_grams = []\n",
        "    # loop each word sequence\n",
        "    # we starts from 1 because 0 has no context\n",
        "    # we stop at second last for the same reason\n",
        "    for sent in corpus:\n",
        "        for i in range(1, len(sent) - 1):\n",
        "            target = word2index[sent[i]]\n",
        "            context = [word2index[sent[i - 1]], word2index[sent[i + 1]]]\n",
        "            for w in context:\n",
        "                skip_grams.append([target, w])\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) #randomly pick without replacement\n",
        "        \n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams[i][0]])  # target, e.g., 2\n",
        "        random_labels.append([skip_grams[i][1]])  # context word, e.g., 3\n",
        "            \n",
        "    return np.array(random_inputs), np.array(random_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  [[5]\n",
            " [3]]\n",
            "Target:  [[3]\n",
            " [1]]\n"
          ]
        }
      ],
      "source": [
        "#testing the method\n",
        "batch_size = 2 # mini-batch size\n",
        "input_batch, target_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "print(\"Input: \",  input_batch)\n",
        "print(\"Target: \", target_batch)\n",
        "\n",
        "#we will convert them to tensor during training, so don't worry..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2, 1), (2, 1))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_batch.shape, target_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Negative Sampling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unigram distribution\n",
        "\n",
        "$$P(w)=U(w)^{3/4}/Z$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "Z = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_count = Counter(flatten(corpus))\n",
        "num_total_words = sum([c for w, c in word_count.items()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_count[',']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_total_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "unigram_table = []\n",
        "\n",
        "for vo in vocab:\n",
        "    unigram_table.extend([vo] * int(((word_count[vo]/num_total_words)**0.75)/Z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'apple': 260,\n",
              "         'dog': 260,\n",
              "         'banana': 260,\n",
              "         'cat': 260,\n",
              "         'fruit': 260,\n",
              "         'animal': 260})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(unigram_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Negative Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def prepare_sequence(seq, word2index):\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return torch.LongTensor(idxs)\n",
        "\n",
        "def negative_sampling(targets, unigram_table, k):\n",
        "    batch_size = targets.size(0)\n",
        "    neg_samples = []\n",
        "    for i in range(batch_size):\n",
        "        nsample = []\n",
        "        target_index = targets[i].item()\n",
        "        while len(nsample) < k: # num of sampling\n",
        "            neg = random.choice(unigram_table)\n",
        "            if word2index[neg] == target_index:\n",
        "                continue\n",
        "            nsample.append(neg)\n",
        "        neg_samples.append(prepare_sequence(nsample, word2index).view(1, -1))\n",
        "    \n",
        "    return torch.cat(neg_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the negative sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_batch  = torch.Tensor(input_batch)\n",
        "target_batch = torch.LongTensor(target_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5, 5, 2],\n",
              "        [5, 5, 4]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_neg = 3\n",
        "negative_sampling(target_batch, unigram_table, num_neg)\n",
        "\n",
        "#{'grapes': 0, 'apple': 1, 'animal': 2, 'cat': 3, 'ice': 4, 'orange': 5, 'dog': 6, 'monkey': 7, 'conda': 8, 'fruit': 9, 'banana': 10}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_batch[1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model\n",
        "\n",
        "$$\\mathbf{J}_{\\text{neg-sample}}(\\mathbf{v}_c,o,\\mathbf{U})=-\\log(\\sigma(\\mathbf{u}_o^T\\mathbf{v}_c))-\\sum_{k=1}^K\\log(\\sigma(-\\mathbf{u}_k^T\\mathbf{v}_c))$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SkipgramNegSampling(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, emb_size):\n",
        "        super(SkipgramNegSampling, self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, emb_size) # center embedding\n",
        "        self.embedding_u = nn.Embedding(vocab_size, emb_size) # out embedding\n",
        "        self.logsigmoid = nn.LogSigmoid()\n",
        "                    \n",
        "    def forward(self, center_words, target_words, negative_words):\n",
        "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
        "        neg_embeds    = -self.embedding_u(negative_words) # [batch_size, num_neg, emb_size]\n",
        "        \n",
        "        positive_score = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "        \n",
        "        negative_score = neg_embeds.bmm(center_embeds.transpose(1, 2))\n",
        "        #[batch_size, k, emb_size] @ [batch_size, emb_size, 1] = [batch_size, k, 1]\n",
        "        \n",
        "        loss = self.logsigmoid(positive_score) + torch.sum(self.logsigmoid(negative_score), 1)\n",
        "                \n",
        "        return -torch.mean(loss)\n",
        "    \n",
        "    def prediction(self, inputs):\n",
        "        embeds = self.embedding_v(inputs)\n",
        "        \n",
        "        return embeds"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size     = 2 # mini-batch size\n",
        "embedding_size = 2 #so we can later plot\n",
        "model          = SkipgramNegSampling(voc_size, embedding_size)\n",
        "num_neg        = 10 # num of negative sampling\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000 | cost: 8.177766 | time: 0m 0s\n",
            "Epoch: 2000 | cost: 4.865495 | time: 0m 0s\n",
            "Epoch: 3000 | cost: 5.729834 | time: 0m 0s\n",
            "Epoch: 4000 | cost: 4.127280 | time: 0m 0s\n",
            "Epoch: 5000 | cost: 3.526144 | time: 0m 0s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch = random_batch(batch_size, corpus)\n",
        "    \n",
        "    #input_batch: [batch_size, 1]\n",
        "    input_batch = torch.LongTensor(input_batch)\n",
        "    \n",
        "    #target_batch: [batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch)\n",
        "    \n",
        "    #negs_batch:   [batch_size, num_neg]\n",
        "    negs_batch = negative_sampling(target_batch, unigram_table, num_neg)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "        \n",
        "    loss = model(input_batch, target_batch, negs_batch)\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Plotting the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'dog', 'banana', 'cat', 'fruit', 'animal', '<UNK>']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#list of vocabs\n",
        "vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "word = vocab[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#numericalization\n",
        "id = word2index[word]\n",
        "id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_tensor = torch.LongTensor([id])\n",
        "id_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-0.4508, -1.7613]], grad_fn=<EmbeddingBackward0>),\n",
              " tensor([[0.7302, 0.8984]], grad_fn=<EmbeddingBackward0>))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get the embedding by averaging\n",
        "v_embed = model.embedding_v(id_tensor)\n",
        "u_embed = model.embedding_u(id_tensor)\n",
        "\n",
        "v_embed, u_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-0.4314, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#average to get the word embedding\n",
        "word_embed = (v_embed + u_embed) / 2\n",
        "word_embed[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's write a function to get embedding given a word\n",
        "def get_embed(word):\n",
        "    id_tensor = torch.LongTensor([word2index[word]])\n",
        "    v_embed = model.embedding_v(id_tensor)\n",
        "    u_embed = model.embedding_u(id_tensor) \n",
        "    word_embed = (v_embed + u_embed) / 2 \n",
        "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocab[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Cosine similarity\n",
        "\n",
        "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
        "\n",
        "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
        "\n",
        "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'dog', 'banana', 'cat', 'fruit', 'animal', '<UNK>']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's try similarity between first and second, and second and third\n",
        "cat          = get_embed('cat')\n",
        "fruit        = get_embed('fruit')\n",
        "animal       = get_embed('animal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  0.9787824396242243\n",
            "cat vs. animal:  -0.6629963816081065\n",
            "cat vs. cat:  1.0\n"
          ]
        }
      ],
      "source": [
        "#numpy version\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "    \n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  0.9787824396242243\n",
            "cat vs. animal:  -0.6629963816081066\n",
            "cat vs. cat:  1\n"
          ]
        }
      ],
      "source": [
        "#scipy version\n",
        "from scipy import spatial\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n",
        "    return cos_sim\n",
        "\n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "dsai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
