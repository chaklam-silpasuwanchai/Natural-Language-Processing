{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GloVE\n",
        "\n",
        "Let's work on implementation of GloVE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Define some very simple data for understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\",\n",
        "                 \"dog cat animal\", \"cat animal dog\", \"cat dog animal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'animal', 'dog'],\n",
              " ['cat', 'dog', 'animal']]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = [sent.split(\" \") for sent in corpus]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['animal', 'cat', 'dog', 'banana', 'fruit', 'apple']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'animal': 0, 'cat': 1, 'dog': 2, 'banana': 3, 'fruit': 4, 'apple': 5}\n"
          ]
        }
      ],
      "source": [
        "#numericalization\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "print(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "#vocab size\n",
        "voc_size = len(vocab)\n",
        "print(voc_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#append UNK\n",
        "vocab.append('<UNK>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['animal', 'cat', 'dog', 'banana', 'fruit', 'apple', '<UNK>']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2index['<UNK>'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#just in case we need to use\n",
        "index2word = {v:k for k, v in word2index.items()} "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build Co-occurence Matrix X"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we need to count the co-occurence of two words given some window size.  We gonna use window size of 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'apple': 3, 'banana': 3, 'fruit': 3, 'dog': 3, 'cat': 3, 'animal': 3})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "X_i = Counter(flatten(corpus)) # X_i\n",
        "X_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('banana', 'apple'),\n",
              " ('banana', 'fruit'),\n",
              " ('apple', 'banana'),\n",
              " ('apple', 'fruit'),\n",
              " ('fruit', 'banana'),\n",
              " ('fruit', 'apple'),\n",
              " ('cat', 'dog'),\n",
              " ('cat', 'animal'),\n",
              " ('animal', 'cat'),\n",
              " ('animal', 'dog'),\n",
              " ('dog', 'cat'),\n",
              " ('dog', 'animal')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make skip gram of one size window\n",
        "skip_grams = []\n",
        "# loop each word sequence\n",
        "# we starts from 1 because 0 has no context\n",
        "# we stop at second last for the same reason\n",
        "for sent in corpus:\n",
        "    for i in range(1, len(sent) - 1):\n",
        "        target = sent[i]\n",
        "        context = [sent[i - 1], sent[i + 1]]\n",
        "        for w in context:\n",
        "            skip_grams.append((target, w))\n",
        "\n",
        "skip_grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({('banana', 'apple'): 1,\n",
              "         ('banana', 'fruit'): 1,\n",
              "         ('apple', 'banana'): 1,\n",
              "         ('apple', 'fruit'): 1,\n",
              "         ('fruit', 'banana'): 1,\n",
              "         ('fruit', 'apple'): 1,\n",
              "         ('cat', 'dog'): 1,\n",
              "         ('cat', 'animal'): 1,\n",
              "         ('animal', 'cat'): 1,\n",
              "         ('animal', 'dog'): 1,\n",
              "         ('dog', 'cat'): 1,\n",
              "         ('dog', 'animal'): 1})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_ik_skipgram = Counter(skip_grams) # Co-occurece in window size 1\n",
        "X_ik_skipgram"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Weighting function\n",
        "\n",
        "GloVe includes a weighting function to scale down too frequent words.\n",
        "\n",
        "<img src = \"figures/glove_weighting_func.png\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#simply a normalized function...don't worry too much\n",
        "def weighting(w_i, w_j, X_ik):\n",
        "        \n",
        "    #check whether the co-occurrences exist between these two words\n",
        "    try:\n",
        "        x_ij = X_ik[(w_i, w_j)]\n",
        "    except:\n",
        "        x_ij = 1  #if does not exist, set it to 1\n",
        "                \n",
        "    x_max = 100 #100 # fixed in paper  #cannot exceed 100 counts\n",
        "    alpha = 0.75\n",
        "    \n",
        "    #if co-occurrence does not exceed 100, scale it based on some alpha\n",
        "    if x_ij < x_max:\n",
        "        result = (x_ij/x_max)**alpha  #scale it\n",
        "    else:\n",
        "        result = 1  #if is greater than max, set it to 1 maximum\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_ik={('animal', 'cat'): 2, ('cat', 'animal'): 2, ('animal', 'dog'): 2, ('dog', 'animal'): 2, ('cat', 'dog'): 2, ('dog', 'cat'): 2, ('banana', 'fruit'): 2, ('fruit', 'banana'): 2, ('banana', 'apple'): 2, ('apple', 'banana'): 2, ('fruit', 'apple'): 2, ('apple', 'fruit'): 2}\n",
            "weighting_dic={('animal', 'animal'): 0.03162277660168379, ('animal', 'cat'): 0.053182958969449884, ('cat', 'animal'): 0.053182958969449884, ('animal', 'dog'): 0.053182958969449884, ('dog', 'animal'): 0.053182958969449884, ('animal', 'banana'): 0.03162277660168379, ('banana', 'animal'): 0.03162277660168379, ('animal', 'fruit'): 0.03162277660168379, ('fruit', 'animal'): 0.03162277660168379, ('animal', 'apple'): 0.03162277660168379, ('apple', 'animal'): 0.03162277660168379, ('animal', '<UNK>'): 0.03162277660168379, ('<UNK>', 'animal'): 0.03162277660168379, ('cat', 'cat'): 0.03162277660168379, ('cat', 'dog'): 0.053182958969449884, ('dog', 'cat'): 0.053182958969449884, ('cat', 'banana'): 0.03162277660168379, ('banana', 'cat'): 0.03162277660168379, ('cat', 'fruit'): 0.03162277660168379, ('fruit', 'cat'): 0.03162277660168379, ('cat', 'apple'): 0.03162277660168379, ('apple', 'cat'): 0.03162277660168379, ('cat', '<UNK>'): 0.03162277660168379, ('<UNK>', 'cat'): 0.03162277660168379, ('dog', 'dog'): 0.03162277660168379, ('dog', 'banana'): 0.03162277660168379, ('banana', 'dog'): 0.03162277660168379, ('dog', 'fruit'): 0.03162277660168379, ('fruit', 'dog'): 0.03162277660168379, ('dog', 'apple'): 0.03162277660168379, ('apple', 'dog'): 0.03162277660168379, ('dog', '<UNK>'): 0.03162277660168379, ('<UNK>', 'dog'): 0.03162277660168379, ('banana', 'banana'): 0.03162277660168379, ('banana', 'fruit'): 0.053182958969449884, ('fruit', 'banana'): 0.053182958969449884, ('banana', 'apple'): 0.053182958969449884, ('apple', 'banana'): 0.053182958969449884, ('banana', '<UNK>'): 0.03162277660168379, ('<UNK>', 'banana'): 0.03162277660168379, ('fruit', 'fruit'): 0.03162277660168379, ('fruit', 'apple'): 0.053182958969449884, ('apple', 'fruit'): 0.053182958969449884, ('fruit', '<UNK>'): 0.03162277660168379, ('<UNK>', 'fruit'): 0.03162277660168379, ('apple', 'apple'): 0.03162277660168379, ('apple', '<UNK>'): 0.03162277660168379, ('<UNK>', 'apple'): 0.03162277660168379, ('<UNK>', '<UNK>'): 0.03162277660168379}\n"
          ]
        }
      ],
      "source": [
        "from itertools import combinations_with_replacement\n",
        "\n",
        "X_ik = {}  #for keeping the co-occurences\n",
        "weighting_dic = {} #scaling the percentage of sampling\n",
        "\n",
        "for bigram in combinations_with_replacement(vocab, 2):\n",
        "    if X_ik_skipgram.get(bigram) is not None:  #matches \n",
        "        co_occer = X_ik_skipgram[bigram]  #get the count from what we already counted\n",
        "        X_ik[bigram] = co_occer + 1 # + 1 for stability issue\n",
        "        X_ik[(bigram[1],bigram[0])] = co_occer+1   #count also for the opposite\n",
        "    else:\n",
        "        pass\n",
        "        \n",
        "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
        "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)\n",
        "\n",
        "print(f\"{X_ik=}\")\n",
        "print(f\"{weighting_dic=}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Prepare train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'fruit']\n",
            "['banana', 'apple', 'fruit']\n",
            "['banana', 'fruit', 'apple']\n",
            "['dog', 'cat', 'animal']\n",
            "['cat', 'animal', 'dog']\n",
            "['cat', 'dog', 'animal']\n"
          ]
        }
      ],
      "source": [
        "for c in corpus:\n",
        "    print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
        "    \n",
        "    #convert to id since our skip_grams is word, not yet id\n",
        "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_coocs  = []\n",
        "    random_weightings = []\n",
        "    random_index = np.random.choice(range(len(skip_grams_id)), batch_size, replace=False) #randomly pick without replacement\n",
        "        \n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams_id[i][0]])  # target, e.g., 2\n",
        "        random_labels.append([skip_grams_id[i][1]])  # context word, e.g., 3\n",
        "        \n",
        "        #get cooc\n",
        "        pair = skip_grams[i]\n",
        "        try:\n",
        "            cooc = X_ik[pair]\n",
        "        except:\n",
        "            cooc = 1\n",
        "        random_coocs.append([math.log(cooc)])\n",
        "        \n",
        "        #get weighting\n",
        "        weighting = weighting_dic[pair]\n",
        "        random_weightings.append([weighting])\n",
        "                    \n",
        "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weightings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  [[0]\n",
            " [1]]\n",
            "Target:  [[1]\n",
            " [2]]\n",
            "Cooc:  [[0.69314718]\n",
            " [0.69314718]]\n",
            "Weighting:  [[0.05318296]\n",
            " [0.05318296]]\n"
          ]
        }
      ],
      "source": [
        "#testing the method\n",
        "batch_size = 2 # mini-batch size\n",
        "input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "\n",
        "print(\"Input: \", input_batch)\n",
        "print(\"Target: \", target_batch)\n",
        "print(\"Cooc: \", cooc_batch)\n",
        "print(\"Weighting: \", weighting_batch)\n",
        "\n",
        "#we will convert them to tensor during training, so don't worry..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model\n",
        "\n",
        "<img src =\"figures/glove.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GloVe(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size,embed_size):\n",
        "        super(GloVe,self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, embed_size) # center embedding\n",
        "        self.embedding_u = nn.Embedding(vocab_size, embed_size) # out embedding\n",
        "        \n",
        "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
        "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
        "        \n",
        "    def forward(self, center_words, target_words, coocs, weighting):\n",
        "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
        "        \n",
        "        center_bias = self.v_bias(center_words).squeeze(1)\n",
        "        target_bias = self.u_bias(target_words).squeeze(1)\n",
        "        \n",
        "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "        \n",
        "        #note that coocs already got log\n",
        "        loss = weighting*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
        "        \n",
        "        return torch.sum(loss)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size     = 10 # mini-batch size\n",
        "embedding_size = 2 #so we can later plot\n",
        "model          = GloVe(voc_size, embedding_size)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000 | cost: 0.050733 | time: 0m 0s\n",
            "Epoch: 2000 | cost: 0.000005 | time: 0m 0s\n",
            "Epoch: 3000 | cost: 0.000000 | time: 0m 0s\n",
            "Epoch: 4000 | cost: 0.000000 | time: 0m 0s\n",
            "Epoch: 5000 | cost: 0.000000 | time: 0m 0s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "    input_batch  = torch.LongTensor(input_batch)         #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch)        #[batch_size, 1]\n",
        "    cooc_batch   = torch.FloatTensor(cooc_batch)         #[batch_size, 1]\n",
        "    weighting_batch = torch.FloatTensor(weighting_batch) #[batch_size, 1]\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = model(input_batch, target_batch, cooc_batch, weighting_batch)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Plotting the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['animal', 'cat', 'dog', 'banana', 'fruit', 'apple', '<UNK>']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#list of vocabs\n",
        "vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "word = vocab[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#numericalization\n",
        "id = word2index[word]\n",
        "id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_tensor = torch.LongTensor([id])\n",
        "id_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-0.4547,  0.0719]], grad_fn=<EmbeddingBackward0>),\n",
              " tensor([[-0.9237,  0.5004]], grad_fn=<EmbeddingBackward0>))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get the embedding by averaging\n",
        "v_embed = model.embedding_v(id_tensor)\n",
        "u_embed = model.embedding_u(id_tensor)\n",
        "\n",
        "v_embed, u_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.2861, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#average to get the word embedding\n",
        "word_embed = (v_embed + u_embed) / 2\n",
        "word_embed[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's write a function to get embedding given a word\n",
        "def get_embed(word):\n",
        "    id_tensor = torch.LongTensor([word2index[word]])\n",
        "    v_embed = model.embedding_v(id_tensor)\n",
        "    u_embed = model.embedding_u(id_tensor) \n",
        "    word_embed = (v_embed + u_embed) / 2 \n",
        "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocab[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Cosine similarity\n",
        "\n",
        "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
        "\n",
        "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
        "\n",
        "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['animal', 'cat', 'dog', 'banana', 'fruit', 'apple', '<UNK>']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's try similarity between first and second, and second and third\n",
        "cat          = get_embed('cat')\n",
        "fruit        = get_embed('fruit')\n",
        "animal       = get_embed('animal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  0.4297538348963393\n",
            "cat vs. animal:  -0.06819172453918752\n",
            "cat vs. cat:  1.0\n"
          ]
        }
      ],
      "source": [
        "#numpy version\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "    \n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  0.4297538348963392\n",
            "cat vs. animal:  -0.06819172453918743\n",
            "cat vs. cat:  1\n"
          ]
        }
      ],
      "source": [
        "#scipy version\n",
        "from scipy import spatial\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n",
        "    return cos_sim\n",
        "\n",
        "print(f\"cat vs. fruit: \",     cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "dsai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
